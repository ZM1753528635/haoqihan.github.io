<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux软件安装管理]]></title>
    <url>%2F2019%2F02%2F12%2FLinux%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[软件包管理软件包的分类 源码包 二进制包 源码包的优点 开源，如果有足够能力，可以修改源代码 可以自由选择所需的功能 软件是编译安装，所有更加适合自己的系统，更加稳定也效率更高 卸载方便 源码包的缺点 安装麻烦，尤其是一些比较大的集合软件 编译过程时间比较长，安装比二进制安装时间长 因为是编译安装，一旦出错会很麻烦 二进制包的优点 包管理系统简单，只通过几个命令就可以实现包的安装，升级，查询和卸载 安装速度比源码包要快 二进制的缺点 经过编译，不能看到源代码了 功能选择不如源码包灵活 依赖性 rpm命令管理RPM包命名规则1234567httpd-2.2.15-15.el6.centos.1.i686.rpm - httpd 软件包名 - 2.2.15 软件版本 - 15 软件发布的次数 - el6.centos 适合的linux的平台 - i686 适合的硬件平台 - rpm rpm包的扩展名 RPM包的依赖性 树形依赖：a -&gt; b -&gt; c 环形依赖：a - &gt; b -&gt; c -&gt; a 模块依赖：查询网站：www.rpmfind.net 安装命令包全名与包名 包全名：操作的包是没有按照的软件包时，使用包全名，而且要注意路径 包名：操作已经安装的软件包时，使用包名是搜索/var/lib/rpm 中的数据库 RPM安装123456rpm -ivh 包全名选项： -i 安装 -v 显示详细信息 -h 显示进度 --nodeps 不检测依赖性 升级和卸载RPM包升级123rpm -Uvh 包全名选项： -U 升级 RPM包卸载1234rpm -e 包名选项： -e 卸载 --nodeps 不检查依赖性 RPM包查询查询是否安装123456rpm -q 包名# 查询是否安装-q 查询rpm -qa# 查询所有安装的rpm包 查询软件包的详细信息1234rpm -qi 包名选项： -i 查询软件信息 -p 查询未安装包信息 查询包中文件安装位置1234rpm -ql 包名选项： -l 列表 -p 查询未安装包信息 RPM包默认安装位置 地址 详细 /etc/ 配置文件安装目录 /usr/bin/ 可执行的命令安装目录 /usr/lib/ 程序所使用的函数库保存位置 /usr/share/doc/ 基本的软件使用手册保存位置 /usr/share/man/ 帮助文件保存位置 查询系统文件属于哪个rpm包123rpm -qf 系统文件名选项： -f 查询系统文件属于哪个软件包 查询软件包的依赖性1234rpm -qR 包名选项： -R 查询软件包的依赖性 -p 查询未安装包的信息 RPM包校验1234567891011121314151617181920rpm -V 已安装的包名选项： -V 校验指定RPM包的文件 验证内容中的8个信息的具体内容 s 文件大小是否改变 M 文件的类型或文件权限（rwx）是否被改变 5 文件MD5校验是否改变（可以看成文件内容是否被改变） D 设备的主从代码是否改变 L 文件路径是否改变 U 文件的属主（所有者）是否改变 G 文件的属组是否改变 T 文件的修改实际是否改变文件类型 c 配置文件 d 普通文件 g “鬼”文件，就是该文件不应该被这个RPM所包含的 L 授权文件 r 描述文件 RPM包中的文件提取12345678910111213rpm2cpio 包全名 | cpio -idv .文件绝对路径rpm2cpio# 将rpm包转换为cpio格式的命令cpio # 是一个标准工具，他用于创建软件档案文件和从档案文件中提取文件cpio 选项 &lt; [文件|设备]选项： -i copy-in模式，还原 -d 还原时自动新建目录 -v 显示还原过程 yum在线安装yum源文件12345678910vim /etc/yum.repos.d/CentOS-Base.repo [base] 容器说明，一定要放在[]中name 容器说明，可以自己随便写mirrorlist 镜像站点，这个可以注释baseurl yum源服务器的地址，可以自己更改自己喜欢的yum源enabled 此容器是否生效，1代表生效，0代表不生效gpgcheck 如果是1是指RPM数字保证书生效，如果是0则是不生效gpgkey 数字保证书的公钥文件保存位置，不用修改failovermethod=priority 光盘搭建yum源123456789101112131415161.挂载光盘mkdir /mnt/cdrom# 建立挂载点mount /dev/cdrom /mnt/cdrom/# 挂载光盘2.使网络yum源失效cd /etc/yum.repos.d/# 进入yum源目录mv CentOS-Base.repo CentOS-Base.repo.bak# 修改yum源文件后缀名，使其失效3.使光盘yum源生效vim CentOS-Media.repo# 修改位置为光盘挂载位置 yum命令常用yum命令12345678910111213141516171819202122查询yum list# 查询所有可用软件包列表yum search 关键字# 搜索服务器上所有和关键字相关的包安装yum -y install 包名选项： install 安装 -y 自动回答yes 升级yum -y update 包名选项： update 升级 卸载yum -y remove 包名选项： remove 卸载 yum软件组管理命令12345678yum grouplist# 列出所有可用的软件组列表yum grouplist 软件组名# 安装指定软件组，组名可用由grouplist查询出来yum groupremove 软件组名# 卸载指定软件组 源码包安装脚本安装]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux网络管理]]></title>
    <url>%2F2019%2F02%2F11%2Flinux%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[网络基础OSI七层模型123ISO:国际标准化组织OSI：开放系统互联模型IOS：苹果操作系统 名称 详细 应用层 用户接口 表示层 数据的表示形态，功能特定的实现：加密 会话层 对应用会话管理，同步 传输层 可靠与不可靠传输，传输前的错误检测，流控 网络层 提供逻辑地址，选路 数据链路层 成帧，用MAC访问媒介，错误检测与修正 物理层 设备之间的比特流的传输，物理接口，电气特性等 TCP/IP四层模型OSI七层与TCP/IP的对应关系 12345678910111213141516171819202122232425262728293031应用层表示层 应用层会话层传输层 传输层网络层 网际互联层数据链路层物理层 网络接口层网络接口层 网络接入层与OSI参考模型中的物理层和数据链路层相对应，他负责监视数据在主机和网络之间的交换 事实上，TCP/IP本身并未定义该层协议，而又参与互联的各网络接入层进行连接，地址解析协议（ARP） 工作在此层，即OSI参考模型的数据链路层网际互联层 网际互联层对应于OSI参考模型的网络层，主要解决主机到主机的通信问题，他所包含的协议涉及数据包 在整个网络上的逻辑传输，该层有三个主要协议：网际协议（IP），互联网组管理协议（IGMP）和互联网 控制报文协议（ICMP）传输层 传输层对应OSI参考模型的传输层，为应用层实体提供端到端的通信功能，保证了数据包的顺序传送及 数据的完整性，该层定义了两个主要协议：传输控制协议（TCP）和 用户数据报协议（UDP）应用层 应用层对应OSI参考模型的高层，为用户提供所需要提供的各种服务，如：FTP，Telnet，DNS，SMTP等TCP/IP模型与OSI模型的比较共同点 OSI参考模型和TCP/IP参考模型都采用了分层结构的概念 都能够提供面向连接和无连接两种通信服务机制不同点 前者是七层，后者是四层 对可靠性要求不同 OSI模型在协议开发前设计的，具有通用性，TCP/IP是现有协议然后集然后建立模型，不适用与非TCP/IP网络 实际市场应用不同（OSI模型只是理论上的模型，并没有成熟的产品，而TCP/IP已经成为“实际上的国际标准”） IP地址ip地址分类 子网掩码的使用1234三种： 255.255.255.0 255.255.0.0 255.0.0.0 端口作用123456789101112端口号是什么？ 计算机有2的16次方的端口号，可以通过端口找到对应服务端口号的分类？常见的端口号？ FTP（文件传输协议）：端口号 20 21 SSH（安全shell协议）：端口号 22 telnet（远程登录协议）：端口号 23 DNS（域名系统）： 端口号 53 http（超文本传输协议）：端口号 80 https（超文本传输安全协议）：端口号 443 SMTP（简单邮件传输协议）：端口号 25 POP3(邮局协议3代)： 端口 110 查看本机启用的端口1234netstat -an选项： -a 查看所有连接和监听端口 -n 显示IP地址和端口号，而不显示域名和服务名 DNS作用1234567891011121314将域名解析为IP地址 客户机向DNS服务器发送域名查询请求 DNS服务器告知客户机Web服务器的ip地址 客户机与web服务器进行通信从查询方式划分 递归查询 要么作出成功响应，要么一直作出查询失败的响应，一般客户机和服务区之间属递归查询，即客户机向DNS服务器 发送请求后，若DNS服务器本身不能解析，则会向另外的DNS服务器发起查询请求，得到的请求转交给客户机 迭代查询 服务器收到一次迭代查询回复一次查询结果，但是这个结果不一定是目标IP与域名的映射关系，也可以是其他DNS服务器的地址 从查询内容上划分 正向查询由域名查询IP地址 反向查询由IP地址查找域名 网关作用 网关又称为网间连接器，协议转换器 网关在网络层实现网络互连，是最复杂的网络互连设备，近用于两个高层协议不同的网络互连 网关即可用于广域互连，也可以用于局域网互连 网关是一种充当转换重任的服务器和路由器 123网关的作用 1.网关在所有内网计算机访问的不是本网段的数据报时使用 2.网关负责将内网ip转换为公网ip，公网ip转换为内网ip linux网络配置linux配置IP地址1234567service network restart# 重启网络1.ifconfig命令临时配置IP地址2.setup工具永久配置IP地址3.修改网络配置文件4.图形界面 linux网络配置文件网卡配置文件123456789101112131415vim /etc/sysconfig/network-scripts/ifcfg-eth0# 查看网卡配置DEVICE=eth0 网卡设备名BOOTPROTO=static 是否自动获取IP（none，static，dhcp）HWADDR=00：0c:29:17:c4:09 MAC地址NM_CONTROLLED=yes 是否可以由Network Manager图形管理工具托管ONBOOT=yes 是否随网络服务启动，eth0生效TYPE=Ethernet 类型为以太网UUID="asdasdasda" 唯一标识码IPADDR=172.17.189.129 IP地址NETMASK=255.255.240.0 子网掩码GATEWAY=192.168.19.0 网关DNS1=8.8.8.8 DNSIPV6INIT=no IPV6没有启用USERCTL=no 不允许非root用户控制此网卡 主机名文件123456789vim /etc/sysconfig/network# 查看主机名NETWORKING_IPV6=noPEERNTP=noGATEWAY=172.17.191.253HOSTNAME=root 主机名hostname [主机名]# 查看或临时设置主机名命令 DNS配置文件123456vim /etc/resolv.conf # 查看DNS配置文件nameserver 100.100.2.136 设置dnsnameserver 100.100.2.138options timeout:2 attempts:3 rotate single-request-reopen 虚拟机网络参数配置12345678910111213141516171819202122231.配置linux的IP地址 setup # 修改ip地址 2.启动网卡vim /etc/sysconfig/network-scripts/ifcfg-eth0把 ONBOOT=no改为 ONBOOT=yesservice network restart# 重启网络服务3.修改UUID vim /etc/sysconfig/network-scripts/ifcfg-eth0 # 删除MAC地址行 rm -rf /etc/udev/rules.d/75-persistent-net-generator.rules # 删除网卡和MAC地址绑定文件 重启系统 4.设置网络连接方式5.修改桥接网卡 Linux网络命令网络环境查看命令查看网络状态1ifconfig 查看与配置网络状态命令 关闭和启动网卡12345ifdown 网卡设备名# 禁用该网卡设备ifup 网卡设备名# 启用该网卡设备 查询网络状态123456789101112131415netstat 选项选项： -t 列出TCP协议端口 -u 列出UDP协议端口 -n 不使用域名和服务名，而使用IP地址和端口号 -l 仅列出在监听状态网络服务 -a 列出所有的网络连接 netstat -rn# 查看网关route -n# 查看路由列表route add default gw 192.168.19.1# 临时设定网关 域名解析命令12345yum install bind-utils -y# 下载nslookupnslookup [主机名或IP]# 进行域名与IP地址解析 网络测试命令ping命令1234ping [选项] ip或域名# 探测指定IP或域名的网络情况选项： -c 次数指定ping包的次数 telnet命令123telnet [域名或IP] [端口]# 远程管理与端口探测命令telnet 192.168.19.1 80 traceroute命令1234traceroute [选项] IP或域名# 路由跟踪命令选项： -n 使用IP，不使用域名，速度更快 wget命令12wget http：//.........# 下载命令 tcpdump命令123456tcpdump -i eth0 -nnX port 21选项： -i 指定网卡接口 -nn 将数据包中的域名与服务转为IP和端口 -X 将十六进制和ASCII码显示数据包内容 port 指定监听的端口 远程登录SSH协议原理12345对称加密算法 采用但要是密码系统的加密方法，同一个秘钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单秘钥加密非对称加密算法 非对称加密算法又称为“公开秘钥加密算法”，非对称加密需要两个秘钥：公开秘钥和私有秘钥 ssh命令123456789ssh 用户名@ip# 远程管理指定Linux服务器scp [-r] 用户名@ip：文件路径 本地路径# 下载文件scp [-r] 本地文件 用户名@ip：上传路径# 上传文件# -r 代表上传下载的是目录 SecureCRT远程管理工具Xshell工具和WinSCP文件传输工具]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础(二)]]></title>
    <url>%2F2019%2F02%2F11%2Flinux%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[磁盘管理df 查看磁盘分区使用状况12345678选项： -l 仅显示本地磁盘（默认） -a 显示所有文件系统的磁盘使用情况，包含/proc/ -h 以1024进制计算最适合的单位显示磁盘容量 -H 以1000进制计算最适合的单位显示磁盘容量 -T 显示磁盘分区类型 -t 显示指定类型文件系统的磁盘分区 -x 不显示指定类型文件系统的磁盘分区 du 统计磁盘的文件大小1234567选项： -b 以byte为单位统计文件 -k 以kb为单位统计文件 -m 以MB为单位统计文件 -h 按照1024进制以最适合的单位统计文件 -H 按照1000进制以最适合的单位统计文件 -s 指定统计目标 分区的概念 第一 主分区和扩展分区总数不能超过4个 第二 扩展分区最多只能有一个 第三 扩展分区不能直接存取数据 1分区： fdisk来分区 分区模式值MBR 主分区不超过4个 单个分区容量最大2TB 分区模式之GPT 主分区的个数“几乎”没有限制 单个分区容量“几乎”没有限制 parted的使用123456789101112parted #分区工具选项： help 查看帮助信息 mklabel gpt 指定使用gpt来分区 select /dev/sdc 切换分区 mkpart 添加分区 cancel 取消操作 print 查看目前分区情况 rm 分区编号 删除分区 mkpart 分区名称 起始位置 结束位置# 使用命令分区 mkfs的使用1234567mkfs.ext3 /dev/sdb# 把/dev/sdb 分区格式化为ext3文件系统格式mkfs -t ext4 /dev/sdb2# 把/dev/sdb2 分区格式化为ext4文件系统格式# 只有主分区和逻辑分区可以格式化，其他分区不可以 挂载分区12345678mount /dev/sdb /mnt/xxx# 把/dev/sdb挂载到/mnt/xxx下umount /mnt/xxx# 把挂载的分区卸载掉vim + /etc/fstab# 修改系统的挂载，可以自动挂载 swap交换分区12345678910111213如何为硬盘添加swap交换分区 - 第一，建立一个普通的linux分区 - 第二，修改分区类型的16进制编码 - 第三，格式化交换分区 - 第四，启用交换分区 mkswap /dev/sdb # 格式化为swap交换分区swapon /dev/sdb # 启动分区swapoff /dev/sdb # 关闭分区 用户和用户组用户和用户组信息存储位置1234567891011121314用户：使用操作系统的人用户组：具有相同系统权限的一组用户/etc/group 存储当前系统中所有用户组信息 - Group： x ：123 ：abc，def，xxx - 组名： 组密码占位符：组编号：组中用户列表/etc/gshadow 存储当前系统中用户组密码信息 - group： *： ： abc，def，xxx - 组名： 组密码： 组管理者： 组中用户名列表/etc/passwd 存储当前系统中所有用户信息 - user ： x ：123 ：456 ：xxxxx ：/home/user :/bin/bash - 用户名：密码占位符：用户编号：用户组编号 ：用户注释信息：用户主目录 ：shell类型/etc/shadow 存储当前系统中所有用户的密码信息 - user：$6$h26yil8F$X3OPNjL....：：：：： - 用户名：密码（加密的）：：：：： 用户组相关命令123456789101112131415161718192021groupadd 组名 添加用户组# 创建用户组选项： -f 如果组存在，则强制退出成功 -g 指定组id -h 帮助信息 -p 组密码 -r 创建一个系统账户 groupmod 修改用户组选项： -n 修改名称 -g 修改组id groupmod -n market sexy # 修改组名 把sexy改为marketgroupmod -g 668 market# 修改组编号groupdel 删除用户组 用户相关命令12345678910111213141516171819202122232425262728useradd 创建用户选项： -g 后面加组名和用户名，就是把这个用户添加到这个组中 -d 可以指定家目录 -G 指定附属组例子： useradd -g 组名 用户名 useradd -d /home/xxxx 用户名 useradd -g 主组 -G 附属组1，附属组2 用户名usermod 修改用户选项： -c 修改用户备注信息 -l 修改用户名称 -d 修改家目录 -g 修改用户的主用户组例子： usermod -c 注释内容 用户名 usermod -l 新用户名 旧用户名 usermod -d 家目录 用户名 userdel 删除用户选项: -r 删除用户时，连同用户家目录一块删除touch /etc/nolog# 除了root用户，其他用户都不能登录 进阶命令123456789101112131415161718192021222324252627282930313233343536373839passwd -l 用户名# 锁定用户passwd -u 用户名# 解锁用户passwd -d 用户名# 清空用户密码gpasswd -a 用户名 用户组# 给这个用户添加一个附属组gpasswd -d 用户名 用户组# 给这个用户删除一个附属组gpasswd 组名# 修改用户组密码newgrp 组名# 切换用户组su 切换用户whoami # 显示当前登录用户id 用户名# 显示指定用户信息，包括用户编号，用户名# 主要组编号及名称，附属组列表groups 用户名# 显示用户所在的所有用户组chfn 用户名# 设置用户资料，依次输入用户资料finger 用户名# 显示用户详细信息]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础（一）]]></title>
    <url>%2F2019%2F02%2F07%2Flinux%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Linux安装虚拟机的安装Vmware官网 虚拟机的使用系统分区linux系统安装centos6的文件系统类型是ext4 linux安装时至少划分根分区 / 和SWAP分区 setup工具配置IP地址 linux的常用命令命令基础格式1234567[root@root ~]# 其中： root（1）： 当前登录用户 root（2）：主机名 ~ ：当前所在目录（~ 表示家目录） # ：超级用户提示符 $ :普通用户的提示符 12345命令 [选项] [参数]注意：个别命令使用不遵循此格式 当有多个选项的时候，可以写在一起 简化选项和完整选项 -a 等于 --al 查询目录中的内容： ls 1234567891011121314151617ls 【选项】 【文件或目录】选项： -a 显示所有文件，包括隐藏文件 -l 显示详细信息 -d 查看目录属性 -h 人性化显示文件大小 -i 显示inode-rw-r--r-- 1 root root 332 Feb 6 19:26 main.go - 文件类型（-文件 d 目录 |软链接文件） rw- r-- r-- u所有者 g所属组 o其他人 r读 w写 x执行 root 属主 root 属组 332 文件大小 Feb 6 19:26 最后一次更改的时间 main.go 文件名称 文件处理命令目录处理命令建立目录： mkdir 123mkdir -p [目录名] -p 递归创建 命令英文原意： make directories 切换所在目录： cd 123456789101112切换所在目录： cd 命令英文原意： change directory简化操作 cd ~ 进入当前用户的家目录 cd 和cd ~一样 cd - 进入上一次目录 cd .. 进入上一级目录 cd . 进入当前目录 相对路径和绝对路径 相对路径：参照当前所在目录，进行查找 绝对路径：从根目录开始指定，一级一级递归查找，在任何目录下都能进入指定位置 查询所在目录位置： pwd 12pwd命令英文原意：print working directory 删除空目录：rmdir 12rmdir [目录名]命令英文原意：remove empty directories 文件处理命令删除文件或目录：rm 12345rm -rf [文件或目录] 命令英文原意：remove选项： -r 删除目录 -f 强制 复制命令：cp 1234567cp [选项] [原文件或目录] [目标目录]命令英文原意：copy选项： -r 复制目录 -p 连带文件属性复制 -d 若源文件是链接文件，则复制链接属性 -a 相当于 -pdr 剪切或改名命令：mv 12mv [原文件或目录] [目标目录]命令英文原意：move 常用的目录 / 根目录 /bin 命令保存目录(普通用户可以读取命令) /boot 启动目录，启动相关文件 /dev 设备文件保存目录 /etc 配置文件保存目录 /home 普通用户的家目录 /lib 系统库保存目录 /mnt 系统挂载目录 /media 挂载目录 / root 超级用户的家目录 /tmp 临时目录 /sbin 命令保存目录（超级用户才能使用的目录） /proc 直接写入内存的 /sys /user 系统软件资源目录 /user/bin/系统命令 （普通用户） /user/sbin/系统命令 （超级用户） /var 系统相关文档内容 链接命令链接命令：ln 123456789101112131415ln -s [原文件] [目标文件]命令英文原意：link功能描述：生成链接文件 选项： -s 创建软连接硬链接的特征： 1.拥有相同的i节点和存储block块，可以看做同一个文件 2.可通过i节点识别 3.不能跨分区 4.不能针对目录使用软连接特征 1.类似windows快捷方式 2.软链接拥有自己的i节点和block块，但数据块只保存原文件的文件名和i节点，并没有实际的文件数据 3.lrwxrwxrwx l软连接，软连接的文件权限都是lrwxrwxrwx 4.修改任意文件，另一个都改变 5.删除原文件，软连接不能使用 文件搜索命令locate命令格式1234567891011121314151617181920212223locate 文件名在后台数据库中按文件名搜索，搜索速度更快./var/lib/mlocate# locate命令所搜索的后台数据库updatedb更新数据库updatedb的配置文件/etc/updatedb.confcat /etc/updatedb.conf PRUNE_BIND_MOUNTS = "yes" PRUNEFS = "9p afs anon_inodefs auto autofs bdev binfmt_misc cgroup cifs coda configfs cpuset debugfs devpts ecryptfs exofs fuse fuse.sshfs fusectl gfs gfs2 gpfs hugetlbfs inotifyfs iso9660 jffs2 lustre mqueue ncpfs nfs nfs4 nfsd pipefs proc ramfs rootfs rpc_pipefs securityfs selinuxfs sfs sockfs sysfs tmpfs ubifs udf usbfs fuse.glusterfs ceph fuse.ceph" PRUNENAMES = ".git .hg .svn" PRUNEPATHS = "/afs /media /mnt /net /sfs /tmp /udev /var/cache/ccache /var/lib/yum/yumdb /var/spool/cups /var/spool/squid /var/tmp /var/lib/ceph" 第一行PRUNE_BIND_MOUNTS="yes"的意思是：是否进行限制搜索。第二行是排除检索的文件系统类型，即列出的文件系统类型不进行检索。第三行表示对哪些后缀的文件排除检索，也就是列在这里面的后缀的文件跳过不进行检索。不同后缀之间用空格隔开。第四行是排除检索的路径，即列出的路径下的文件和子文件夹均跳过不进行检索。updatedb之后使用locate仍然找不到想要文件可以检查挂载的目录是否被忽略了 命令搜索命令whereis与which123456789whereis 命令名 # 搜索命令所在路径及帮助文档所在位置选项： -a： 查看所有的选项 -b： 只查找可执行文件 -m： 只查找帮助文件which 命令名$PATH :系统环境 文件搜索命令find1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950find [搜索范围] [搜索条件]# 搜索文件find / -name main.go# 避免大范围搜索，会非常耗费系统资源# find是在系统当中搜索符合条件的文件名，如果需要匹配，使用通配符匹配，通配符是完全匹配linux的通配符* 匹配任意内容？ 匹配任意一个字符[] 匹配任意一个括号内的字符find /root -iname main.go# 不区分大小写find /root -user root# 按照所有者搜索find /root -nouser# 查找没有所有者的文件find /var/log/ -mtime +10# 查找10天前修改的文件-10 10天内修改的文件10 10天当天修改的文件+10 10天前修改的文件atime 文件访问时间ctime 改变文件属性mtime 修改文件内容find . -size 25k# 查找当前目录大小是25kb的文件-25k 小于25kb的文件25k 等于25kb的文件+25k 大于25kb的文件find . inum 262422# 查找i节点是262422的文件find /etc -size +20k -a -size -50k# 查找/etc目录下，大于20kb并且小于50kb的文件-a and 逻辑与，两个条件都满足-o or 逻辑或，两个条件满足一个即可find /etc -size +20k -a -size -50k -exec ls -lh &#123;&#125;\;# 查找/etc目录下，大于20kb并且小于50kb的文件，并显示详细信息# -exec/-ok 命令 &#123;&#125;\; 对搜索结果执行操作 字符串搜索命令grep123456789grep [选项] 字符串 文件名# 在文件当中匹配符合条件的字符串选项： -i 忽略大小写 -v 取反find命令和grep命令的区别find命令：在系统当中搜索符合条件的文件名，如果匹配，使用通配符，通配符是完全匹配grep命令：在文件中搜索符合条件的字符串，如果需要匹配，使用正则进行匹配，正则表达式包含匹配 帮助命令帮助命令man12345678910111213141516171819202122232425man 命令# 获取指定命令帮助man ls# 查看ls的帮助man的级别1： 查看命令的帮助2： 查看可被内核调用的函数的帮助3： 查看函数和函数库的帮助4： 查看特殊文件的帮助（主要是/dev目录下的文件）5： 查看配置文件的帮助6： 查看游戏的帮助7： 查看其它杂项的帮助8： 查看系统管理员可用命令的帮助9： 查看内核相关的帮助man f 命令 == whatis 命令# 查看命令有几个级别man -1 passwd# 查看passwd命令帮助apropos 命令# 查看所有包含该命令帮助 其他帮助命令123456789101112131415161718192021命令 --help# 获取命令选项的帮助例如： ls --helphelp shell内部命令# 获取shell 内部命令的帮助例如 whereis cd # 确定是否是shell内部命令 help cd # 获取内部命令的帮助info 命令 -回车： 进入子帮助页面（带有*号标记） -u： 进入上一层页面 -n： 进入下一层帮助小节 -p： 进入上一个帮助小节 -q： 退出 压缩与解压缩命令常用压缩格式：.zip .gz .bz2 .tar.gz .tar.bz2 .zip压缩格式12345678zip 压缩文件名 原文件# 压缩文件zip -r 压缩文件名 源目录# 压缩目录unzip 压缩文件# 解压缩 .zip文件 .gz格式压缩123456789101112131415gzip 原文件# 压缩为.gz格式的压缩文件，源文件会消失gzip -c 源文件 &gt; 压缩文件# 压缩为.gz格式，源文件保留# 例如 gzip -c cangls &gt; cangls.gzgzip -r 目录# 压缩目录下所有的子文件，但是不能压缩目录gzip -d 压缩文件# 解压缩文件gunzip 压缩文件# 解压缩文件 .bz2格式压缩12345678910111213bzip2 源文件# 压缩为.bz2格式，不保留源文件bzip2 -k 源文件# 压缩之后保留源文件### bzip2命令不能压缩目录bzip2 -d 压缩文件# 解压缩 -k保留压缩文件bunzip2 压缩文件# 解压缩 -k保留压缩文件 打包命令tar123456789101112131415# 压缩tar -cvf 打包文件名 源文件选项： -c 打包 -v 显示过程 -f 指定打包后的文件名例如： tar -cvf login.tar login# 解压tar -xvf 打包文件名选项： -x 解打包例如： tar -xvf login.tar .tar.gz压缩格式1234567压缩tar -zcvf 压缩包名.tar.gz 源文件选项： -z 压缩为.tar.gz格式tar -zxvf 压缩包名.tar.gz选项： -x 解压缩.tar.gz格式 .tar.bz2压缩格式12345678910111213141516压缩tar -jcvf 压缩包名.tar.bz2 源文件选项： -j 压缩为.tar.bz2格式 tar -jcvf /tmp/压缩包名.tar.bz2 源文件# 压缩到指定目录下解压缩tar -jxvf 压缩包名.tar.bz2选项： -x 解压缩.tar.bz2格式 -t 测试一下，压缩包中有什么tar -jxvf 压缩包名.tar.bz2 -C /tmp/...# 指定解压缩位置 关机和重启命令shutdown命令1234567891011121314151617181920212223# 关机命令shutdown [选项] 时间选项： -c 取消前一个关机命令 -h 关机 -r 重启haltpoweroffinit 0# 重启命令rebootinit 6# 查看当前系统运行级别runlevel# N：代表在进入3之前的级别 3：代表多用户# 修改系统默认运行级别cat /etc/inittab# 退出登录logout 系统运行级别 0 关机 1 单用户 2 不完全多用户，不含NFS服务 3 完全多用户 4 未分配 5 图形界面 6 重启 其他常用命令挂载命令12345678910111213141516171819202122232425262728293031323334351.查询与自动挂载mount# 查询系统中已经挂载的设备mount -a# 依据配置文件/etc/fstab内容自动挂载2.挂载命令格式mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点选项： -t 文件系统：加入文件系统类型来指定挂载类型，可以ext3，ext4，iso9660等文件系统 -o 特殊选项：可以指定挂载的额外选项 3.挂载光盘mkdir /mnt/cdrom/# 建立挂载点mount -t iso9660 /dev/cdrom /mnt/cdrom/# 挂载光盘mount /dev/sr0 /mnt/cdrom/# 挂载光盘4.卸载命令umount 设备文件名或挂载点umount /mnt/cdrom5.挂载u盘fdisk -l# 查看U盘设备名称mount -t vfat /dev/sdb1 /mnt/usb/# 注意：Linux默认是不支持NTFS文件系统的 用户登录查看12345678910111213141516171819202122232425w 用户名命令输出： USER 登录的用户名 TTY 登录终端 FROM 从哪个ip地址登录的 LOGIN@ 登录时间 IDLE 用户闲置时间 JCPU 指的是该终端连接的所有进程占用的时间，这个时间并不包括过去的后台作业时间，但却包括当前正在运行的后台作业所占用的时间 PCPU 是指当前进程所占用的时间 WGAT 当前正在运行的命令who命令输出 用户名 登录终端 登录时间（登录来源ip地址）last和lastloglast命令默认读取/var/log/wtmp文件数据命令输出 用户名称 登录终端 登录ip 登录时间 退出时间（在线时间） shell基础shell概述1.shell的两种主要语法类型有Bourne和C，这两种语法彼此不兼容，Bourne家族主要包括sh、Bash、psh、zsh；C家族包括：csh、tcsh 1vi /etc/shells # 查看支持的shell 脚本执行方式echo输出命令123echo [选项] [输出内容]选项： -e 支持反斜线控制的字符转换 Bash的基本功能命令别名和快捷键1234567891011alias # 查看所有命令的别名alias 别名="原命令"# 设定命令别名vi ~/.bashrc# 写入环境变量配置文件unalias 别名# 删除别名 命令生效顺序 第一顺位执行用绝对路径或相对路径执行的命令 第二顺位执行别名 第三顺位执行Bash的内部命令 第四顺位执行按照￥PATH环境变量定义的目录查找顺序找到的第一个命令 快捷键 作用 ctrl + c 强制终止当前命令 ctrl + l 清屏 ctrl + a 光标移动到行首 ctrl + e 光标移动到行尾 ctrl + u 从光标所在位置删除到行首 Ctrl + z 把命令放入后台 Ctrl + r 在历史命令中搜索 历史命令12345history [选项] [历史命令保存文件]选项： -c 清空历史命令 -w 把缓存中的历史命令写入历史命令保存文件~/.bash_history# 历史命令默认保存1000条，可以在环境变量配置文件/etc/profile中进行修改 输出重定向1234567891011121314标准输出重定向 命令 &gt; 文件 # 直接写入，里面有内容就覆盖 命令 &gt;&gt; 文件 # 追加内容标准错误输出重定向： 命令 2&gt; 文件 # 以覆盖的方式把错误信息写入文件 命令 2&gt;&gt; 文件 # 追加写入到文件正确输出和错误输出同时保存 命令 &gt; 文件 2&gt;&amp;1 命令 &gt;&gt; 文件 2&gt;&amp;1 命令 &amp;&gt; 文件 命令 &amp;&gt;&gt; 文件 命令 &gt;&gt; 文件1 2&gt;&gt; 文件2/dev/null # 黑洞 输入重定向12345wc [选项] [文件名]选项： -c 统计字节数 -w 统计单词数 -l 统计行数 多命令顺序执行 多命令执行符 格式 作用 ： 命令1：命令2 多个命令顺序执行，命令之间没有任何逻辑联系 &amp;&amp; 命令1&amp;&amp;命令2 逻辑与 当命令1正确执行，命令2才会执行，否则就不会执行 \ \ 命令1 \ \ 命令2 逻辑或 命令1执行不正确，2才会执行，命令1正确，2就不会执行 123456管道符命令格式： 命令1 | 命令2 # 命令1的正确输出作为命令2的操作对象netstat -an# 查看端口连接和用户连接 通配符 通配符 作用 ？ 匹配一个任意字符 * 匹配0个或多个任意字符 [] 匹配括号中任意一个字符 [-] 匹配括号中任意一个字符如：[a-z] [^] l逻辑非，表示匹配不是括号中的任意字符 [ ^0-9],表示不匹配数字 Bash中其他特殊符号 符号 作用 ‘ ‘ 单引号，在单引号中所有特殊符号，如“$ `（反引号） ”都没有特殊含义 “ “ 双引号，在单引号中所有特殊符号，都没有特殊含义，但“$ `（反引号） 和 \ 是一个例外”都没有特殊含义 反引号，反引号括起来的是命令系统，在bash中会先执行它，和$()作用一样，不过推荐使用 \$ (),因为反引号容易看错 $() 和反引号的作用一样 # # 号代表注释 $ 用于调用变量值，如$PATH \ 转意符，跟在\后面的符号将失去特殊含义]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[devops导论]]></title>
    <url>%2F2019%2F02%2F06%2Fdevops%E5%AF%BC%E8%AE%BA-1%2F</url>
    <content type="text"><![CDATA[DevOps概述个体软件过程敏捷软件开发软件架构演化云原生和容器技术Xaas和IT服务标准DevOps工具链]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[devops导论]]></title>
    <url>%2F2019%2F02%2F06%2Fdevops%E5%AF%BC%E8%AE%BA%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[DevOps和云计算的初识]]></title>
    <url>%2F2019%2F02%2F06%2FDevOps%E5%92%8C%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[什么是云计算云计算跟云没有任何关系 虚拟化（Virtualization）是基础（计算，存储，网络等） 产品服务化（laas，Paas，Saas，Xaas） 弹性伸缩，没有边界 云计算分类 公有云（Aws，阿里云，Azure等） 私有云（Vmware等） 混合云（Azure，Rackspace） 公有云 云服务提供商对基础设施维护 多租户 Pay For Use 私有云 自己维护基础措施 单租户或狭义上的多租户 Pay For Cloud 混合云(专属云) 云服务提供商维护自己的云设施 用户范围内租户隔离 Pay For Use of Cloud 什么是DevOps DevOps = Development + Operations 极速的迭代和快速的用户反馈]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习的基本了解]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[机器学习的目标​ 机器学习是实现人工智能的手段,其主要研究内容时如何利用数据或经验进行学习,改善算法的性能 多领域交叉,涉及概率论、统计学、算法复杂度理论等多门学科 广泛应用于网络搜索、垃圾邮件过滤、推荐系统、广告投放、信用评价、欺诈检测、股票交易和医疗诊断等应用 机器学习的分类 监督学习（Supervised Learning） 无监督学习（Unsupervised Learning） 强化学习（Reinforcement Learning，增强学习） 半监督学习（Semi-supervised Learning） 深度学习（Deep learning） 机器学习模块Scikit-learn 一组简单有效的工具集 依赖python 的Numpy，scipy和matplotlib库 开源和可复用的 Scikit-learn常用函数 应用（Applications） 算法（Algorithm） 分类（Classification） 异常检测，图像识别等 KNN，SVM，etc 聚类（Clustering） 图像分割，群体划分，等 K-Means，谱聚类，etc 回归（Regression） 价格预测，趋势预测，等 线性回归，SVR，etc 降维（Dimension Reduction） 可视化 PCA，NMF，etc sklearn库sklearn是scikit-learn的简称，是一个基于python的第三方模块，sklearn库集成了一些常见的机器学习方法，在进行机器学习任务时，并不需要实现算法，只需要简单的调用sklearn库中提供的模块就能完成大多数的机器学习任务 sklearn库是在Numpy，scipy和matplotlib的基础上开发而成的，因此在安装sklearn之前，请先安装这些依赖库 12# 安装Scikit-learn模块,pip会自动安装其他模块pip3 install Scikit-learn sklearn库的基本功能sklearn库共分为6大部分,分别用于完成分类任务,回归任务,聚类任务,降维任务,模型选择以及数据的预处理 分类任务 分类模型 加载模块 最近邻算法 from sklearn.neighbors import NearestNeighbors 支持向量机 from sklearn.svm import SVC 朴素贝叶斯 from sklearn.naive_bayes import GaussianNB 决策树 from sklearn.tree import DecisionTreeClassifier 集成方法 from sklearn.ensemble import BaggingClassifier 神经网络 from sklearn.neural_network import MLPClassifier 回归任务 回归模型 加载模块 岭回归 from sklearn.linear_model import Ridge Lasso回归 from sklearn.linear_model import Lasso 弹性网络 from sklearn.linear_model import ElasticNet 最小角回归 from sklearn.linear_model import Lars 贝叶斯回归 from sklearn.linear_model import BayesianRidge 逻辑回归 from sklearn.linear_model import LogisticRegression 多项式回归 from sklearn.preprocessing import PolynomialFeatures 聚类任务 聚类方法 加载模块 K-means from sklearn.cluster import KMeans AP聚类 from sklearn.cluster import AffinityPropagation 均值漂移 from sklearn.cluster import MeanShift 层次聚类 from sklearn.cluster import AgglomerativeClustering DBSCAN from sklearn.cluster import DBSCAN BIRCH from sklearn.cluster import Birch 谱聚类 from sklearn.cluster import SpectralClustering 降维任务 降维方法 加载模块 主成分分析 from sklearn.decomposition import PCA 截断SVD和LSA from sklearn.decomposition import TruncatedSVD 字典学习 from sklearn.decomposition import SparseCoder 因子分析 from sklearn.decomposition import FactorAnalysis 独立成分分析 from sklearn.decomposition import FastICA 非负矩阵分解 from sklearn.decomposition import NMF LDA from sklearn.decomposition import LatentDirichletAllocation]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习之有监督学习]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习之无监督学习]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[无监督学习的目标利用无标签的数据学习数据的分布或数据与数据之间的关系被称作为无监督学习 有监督学习与无监督学习最大的区别在于数据是否有标签 无监督学习最常用的场景是聚类和降维 聚类聚类,就是根据数据的”相似性”将数据分为多类的过程 评估两个不同样本之间的相似性,通常使用的方法就是计算两个样本之间的距离,使用不同的方法计算样本间的距离会关系到聚类结果的好坏 欧式距离欧式距离是最常用的一种距离度量方法,源于欧式空间中两点之间的距离 曼哈顿距离曼哈顿距离也称作”城市街区距离”,类似于在城市之中驾车行驶,从一个十字路口到另一个十字路口的距离 马氏距离马氏距离表示数据的协方差距离,是一种尺度无关的度量方式也就是说马氏距离会先将样本点的各个属性标准化,再计算样本间的距离 夹角余弦余弦相似度用向量空间中两个向量夹角的余弦作为衡量两个样本差异的大小,余弦越接近1,说明两个向量夹角越接近0度,表明两个向量越相似 降维降维,就是在保证数据所具有代表性特征或分布的情况下,将高维数据转化为低维数据的过程 数据可视化 精简数据 sklearn.decomposition 算法名称 参数 可扩展性 适用任务 PCA 所降维度和其他超参 大规模数据 信号处理 FastICA 所降维度和其他超参 超大规模数据 图形图像特征提取 NMF 所降维度和其他超参 大规模数据 图形图像特征提取 LDA 所降维度和其他超参 大规模数据 文本数据,主题挖掘 K-means聚类算法k-means算法以k为参数,把N个对象分为k个簇,使簇内具有较高的相似度,而簇间的相似度较低 随机选择k个点作为初始的聚类中心 对于剩下的点,根据与聚类中心的距离,将其归为最近的簇 对每个簇,计算所有点的均值作为新的聚类中心 重复2,3直到聚类中心不再发生改变]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim的使用]]></title>
    <url>%2F2019%2F01%2F16%2Fvim%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[常用指令底行模式常用指令 ：w 写 ：q 退出 ：！ 强制 ：ls 列出打开的所有文件 ：n 切换到后一个文件 ：N 切换到上一个文件 ：15 跳到15行 /xxx 向后搜索 ？xxx 向前搜索 命令模式常用指令 h 光标左移 j 光标下移 k 光标上移 l 光标右移 ctrl + f 向下翻页（front） ctrl + b 向上翻页（back） ctrl + d 向下翻半页（down） ctrl + u 向上翻半页（up） dd 删除光标所在行 o 在光标所在行的下方插入一行并切换到输入模式 yy 复制光标所在的行 p 在光标所在行的下方粘贴 P 在光标所在行的上方粘贴]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础数据结构]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[什么是数据结构 数据结构是指相互之间存在着一种或多种关系的数据元素的集合和该集合中数据元素之间的关系组成。 简单来说，数据结构就是设计数据以何种方式组织并存储在计算机中。比如：列表、集合与字典等都是一种数据结构。 N.Wirth: “程序=数据结构+算法” 数据结构的分类 数据结构按照其逻辑结构可分为线性结构、树结构、图结构 线性结构：数据结构中的元素存在一对一的相互关系 树结构：数据结构中的元素存在一对多的相互关系 图结构：数据结构中的元素存在多对多的相互关系 列表 列表：在其他编程语言中称为“数组”，是一种基本的数据结构类型 关于列表的问题 列表中元素使如何存储的？ 列表提供了哪些基本的操作？ 这些操作的时间复杂度是多少？ 栈 栈(Stack)是一个数据集合，可以理解为只能在一端进行插入或删除操作的列表 栈的特点：后进先出（last-in, first-out） 栈的概念： 栈顶 栈底 栈的基本操作 进栈（压栈）：push 出栈：pop 取栈顶：gettop 栈的python实现 不需要自己定义,使用列表结构即可 进栈函数:append() 出栈函数:pop 查看栈顶函数:li[-1] 队列 队列(Queue)是一个数据集合，仅允许在列表的一端进行插入，另一端进行删除 进行插入的一端称为队尾(rear)，插入动作称为进队或入队 进行删除的一端称为队头(front)，删除动作称为出队 队列的性质：先进先出(First-in, First-out) 双向队列：队列的两端都允许进行进队和出队操作 队列的实现 初步设想:列表+两个下标指针 创建一个列表和两个变量,front变量指向队首,rear变量指向队尾,初始时,front和rear都为0 进队操作:元素写到li[rear]的位置,rear自增1 出队操作:返回li[front]的元素,front自增1 环形队列 环形队列：当队尾指针front == Maxsize + 1时，再前进一个位置就自动到0。 实现方式：求余数运算 队首指针前进1：front = (front + 1) % MaxSize 队尾指针前进1：rear = (rear + 1) % MaxSize 队空条件：rear == front 队满条件：(rear + 1) % MaxSize == front 队列的内置模块 使用方法:from collections import deque 创建队列：queue = deque(li) 进队：append 出队：popleft 双向队列队首进队：appendleft 双向队列队尾出队：pop 链表 链表中每一个元素都是一个对象，每个对象称为一个节点，包含有数据域key和指向下一个节点的指针next。通过各个节点之间的相互连接，最终串联成一个链表。 节点定义 1234class Node(object): def __init__(self, item=None): self.item = item self.next = None 头插法 1234567def createLinkList(li): l = Node() for num in li: s = Node(num) s.next = l.next l.next = s return l 尾插法 12345678def create_linklist_tail(li): head = Node() tail = head for val in li: p = Node(val) tail.next = p tail = p return head 链表节点的插入 12p.next = curNode.nextcurNode.next = p 链表的删除 123p = curNode.nextcurNode.next = curNode.next.nextdel p 双链表 双链表中每个节点有两个指针：一个指向后面节点、一个指向前面节点 节点定义 12345class Node(object): def __init__(self, item=None): self.item = item self.next = None self.prior = None 双链表节点的插入 1234p.next = curNode.nextcurNode.next.prior = pp.prior = curNodecurNode.next = p 双链表节点的删除 1234p = curNode.nextcurNode.next = p.nextp.next.prior = curNodedel p 链表-复杂度分析 列表和链表 按元素值查找 按下标查找 在某元素后插入 删除某元素 链表在插入和删除的操作上明显快于顺序表 链表的内存可以更灵活的分配 试利用链表重新实现栈和队列 链表这种链式存储的数据结构对树和图的结构有很大的启发性 哈希表 哈希表一个通过哈希函数来计算数据存储位置的数据结构，通常支持如下操作： insert(key, value)：插入键值对(key,value) get(key)：如果存在键为key的键值对则返回其value，否则返回空值 delete(key)：删除键为key的键值对 直接寻址表 当关键字的全域U比较小时，直接寻址是一种简单而有效的方法。 直接寻址法技术缺点 当域U很大时,需要消耗大量内存,很不实际 如果域U很大而时间出现的key很少,则大量空间被浪费 无法处理关键字不是数字的情况 哈希 直接寻址表：key为k的元素放到k位置上 改进直接寻址表：哈希（Hashing） 构建大小为m的寻址表T key为k的元素放到h(k)位置上 h(k)是一个函数，其将域U映射到表T[0,1,…,m-1]]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础算法]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[什么是算法?算法(Algorithm):一个计算过程,解决问题的方法 时间复杂度 时间复杂度 :用来评估算法运行效率的一个东西 一般来说,时间复杂度高的算法比时间复杂度低的算法慢 常见的时间复杂度(按照效率排序 O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n2)&lt;O(n2logn)&lt;O(n3) 不常见的时间复杂度 O(n!) O(2n) O(nn)…. 如何一眼判断时间复杂度 循环减半的过程O(logn) 几次循环就是n的几次方的复杂度 12345678910print('hello World') # O(1)for i in range(n): # O(n) print('hello world')for i in range(n): #O(n²) for j in range(n): print('hello world')for i in range(n): #O(n³) for j in range(n): for k in range(n): print('hello world') 空间复杂度空间复杂度: 用来评估算法内存占用大小的一个式子 二分查找代码: 123456# 普通的查找方式def linear_search(data_set,value): for i in range(len(data_set)): # 时间复杂度是O(n) if data_set[i] == value: return i return 1234567891011121314151617181920212223242526# 二分查找# 循环版本def bin_search(data_set,value): low = 0 high = len(data_set) - 1 while low &lt;= high: mid = (low + high) // 2 if data_set[mid] == value: # 时间复杂度O(logn) return mid elif data_set[mid] &gt; value: high = mid-1 else: low = mid + 1# 递归版本def bin_search_rec(data_set,value,low,high): if low &lt;= high: mid = (low + high) // 2 if data_set[mid] == value: return mid elif data_set[mid] &gt; value: return bin_search_rec(data_set,value,low,mid-1) else: return bin_search_rec(data_set,value,mid+1,high) else: return 冒泡排序冒泡排序思路: 首先,列表两个相邻的数,如果前边的比后边的大,那么交换这两个数,如果不大,那就不需要交换 代码关键点: 1.趟 2.无序区 12345678910111213141516171819​```python# 冒泡算法 时间复杂度:O(n²)def bubble_sort(li): for i in range(len(li)): for j in range(i+1,len(li)): if li[i] &gt; li[j]: li[i], li[j] = li[j], li[i]# 冒泡算法优化# 如果冒泡排序中执行一趟而没有交换，则列表已经是有序状态，可以直接结束算法def bubble_sort(li): for i in range(len(li)): exchange = False for j in range(i+1,len(li)): if li[i] &gt; li[j]: li[i], li[j] = li[j], li[i] exchange = True if not exchange: return ​ 1234567891011121314151617181920## 选择排序**选择排序思路:** - 一趟遍历记录最小的数放在第一个位置- 再一趟遍历记录剩余列表中最小的数，继续放置**代码关键点:** 1.无序区 2.最小数的位置```python# 选择排序代码 时间复杂度:O(n²)def select_sort(li): for i in range(len(li)): min_loc = i for j in range(i+1,len(li)): if li[j] &lt; li[min_loc]: min_loc = j if min_loc != i: li[i],li[min_loc] = li[min_loc],li[i] 插入排序插入排序思路 ​ 列表被分为有序区和无序区两部分,最初有序区只有一个元素 ​ 每次从无序区选择一个元素,插入到有序区的位置,直到无序区变空 123456789# 插入排序代码 时间复杂度O(n²)def insert_sort(li): for i in range(1,len(li)): tmp = li[i] j = i - 1 while j&gt;=0 and tmp &lt; li[j]: li[j+1] = li[j] j -= 1 li[j+1] = tmp 快速排序快速排序思路 1.取一个元素p(第一个元素),使元素p归为 2.列表被p分为两部分,左边比p小,右边比p大 3..递归完成排序 1234567891011121314151617# 快速排序 时间复杂度O(nlogn)def quick_sort(data,left,right): if left &lt; right: mid = partition(data,left,right) quick_sort(data,left,mid-1) quick_sort(data,mid+1,right)def partition(data,left,right): tmp = data[left] while left &lt; right: while left &lt; right and data[right] &gt;= tmp: right -= 1 data[left] = data[right] while left &lt; right and data[left] &lt;= tmp: left += 1 data[right] = data[left] data[left] = tmp return left 堆排序树与二叉树的简介 树是一种数据结构 比如：目录结构 树是一种可以递归定义的数据结构 树是由n个节点组成的集合： 如果n=0，那这是一棵空树； 如果n&gt;0，那存在1个节点作为树的根节点，其他节点可以分为m个集合，每个集合本身又是一棵树。 一些概念: 根节点、 叶子节点树的深度（高度） 树的度孩子节点/父节点 子树 两种特殊二叉树 满二叉:一个二叉树，如果每一个层的结点数都达到最大值，则这个二叉树就是满二叉树。 完全二叉树：叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 二叉树的存储方式: 链式存储方式 顺序存储方式(列表) 父节点和左孩子节点的编号下标有什么关系？ 2i+1 i:代表下标 父节点和右孩子节点的编号下标有什么关系？ 2i+2 堆排序 堆: 大根堆：一棵完全二叉树，满足任一节点都比其孩子节点大 小根堆：一棵完全二叉树，满足任一节点都比其孩子节点小 堆的向下调整性质: 假设:节点的左右子树都是堆，但自身不是堆 当根节点的左右子树都是堆时，可以通过一次向下的调整来将其变换成一个堆 堆排序过程: 建立堆 得到堆顶元素，为最大元素 去掉堆顶，将堆最后一个元素放到堆顶，此时可通过一次调整重新使堆有序。 堆顶元素为第二大元素。 重复步骤3，直到堆变空。 1234567891011121314151617181920212223# 堆排序代码 时间复杂度O(nlogn)def sift(data,low,high): i = low j = 2 * i +1 tmp = data[i] while j &lt;= high: if j &lt; high and data[j] &lt; data[j+1]: j += 1 if tmp &lt; data[j]: data[i] = data[j] i = j j = 2*i+1 else: break data[i] = tmp def heap_sort(data): n = len(data) for i in range(n//2-1,-1,-1): sift(data,i,n-1) for i in range(n-1,-1,-1): data[0],data[i] = data[i],data[0] sift(data,0,i-1) 堆排序–内置模块 优先队列：一些元素的集合，POP操作每次执行都会从优先队列中弹出最大（或最小）的元素。 堆——优先队列 Python内置模块——heapq heapify(x) heappush(heap, item) heappop(heap) 利用heapq模块实现堆排序 123456import heapqdef heapsort(li): h = [] for value in li: heappush(h, value) return [heappop(h) for i in range(len(h))] 归并排序假设现在的列表分两段有序，将其合成为一个有序列表,这种操作称为一次归并 123456789101112131415161718192021222324252627# 归并排序 时间复杂度O(logn) 空间复杂度:O(n)def merge(li,low,mid,high): li_tmp = [] i = low j = mid + 1 while i &lt;= mid and j &lt;= high: if li[i] &lt; li[j]: li_tmp.append(li[i]) i += 1 else: li_tmp.append(li[j]) j += 1 while i &lt;= mid: li_tmp.append(li[i]) i += 1 while j &lt;= high: li_tmp.append(li[j]) j += 1 for i in range(len(li_tmp)): li[i+low] = li_tmp[i]def merge_sort(li,low,high): if low &lt; high: mid = (low + high) // 2 merge_sort(li,low,mid) merge_sort(li,mid+1,high) merge(li,low,mid,high) 归并排序实现思路: 分解：将列表越分越小，直至分成一个元素。 终止条件：一个元素是有序的。 合并：将两个有序列表归并，列表越来越大 总结: 一般情况下，就运行时间而言：快速排序 &lt; 归并排序 &lt; 堆排序 三种排序算法的缺点： 快速排序：极端情况下排序效率低 归并排序：需要额外的内存开销 堆排序：在快的排序算法中相对较慢 希尔排序希尔排序思路: 希尔排序是一种分组插入排序算法 首先取一个整数d1=n/2，将元素分为d1个组，每组相邻量元素之间距离为d1，在各组内进行直接插入排序 取第二个整数d2=d1/2，重复上述分组排序过程，直到di=1，即所有元素在同一组内进行直接插入排序。 希尔排序每趟并不使某些元素有序，而是使整体数据越来越接近有序；最后一趟排序使得所有数据有序 123456789101112# 希尔排序 希尔排序的时间复杂度讨论比较复杂，并且和选取的gap序列有关。def shell_sort(li): gap = len(li) // 2 while gap &gt; 0: for i in range(gap,len(li)): tmp = li[i] j = i-gap while j &gt;= 0 and tmp &lt; li[j]: li[j + gap] = li[j] j -= gap li[j+gap] = tmp gap //= 2 计数排序现在有一个列表，已知列表中的数范围都在0到100之间。设计算法在O(n)时间复杂度内将列表进行排序。 创建一个列表，用来统计每个数出现的次数 123456789101112def count_sort(li,max_num): count = [0 for i in range(max_num+1)] for num in li: count[num] += 1 i = 0 for num , m in enumerate(count): for j in range(m): li[i] = num i += 1li = [1,2,3,4,5,8,6,3,2,1,4]count_sort(li,8)print(li) 桶排序 在计数排序中，如果元素的范围比较大（比如在1到1亿之间），如何改造算法？ 桶排序(Bucket Sort)：首先将元素分在不同的桶中，在对每个桶中的元素排序。 桶排序的表现取决于数据的分布。也就是需要对不同数据排序时采取不同的分桶策略。 平均情况时间复杂度：O(n+k) 最坏情况时间复杂度：O(n2k) 空间复杂度：O(nk) 基数排序 多关键字排序：加入现在有一个员工表，要求按照薪资排序，年龄相同的员工按照年龄排序。 先按照年龄进行排序，再按照薪资进行稳定的排序。 对32,13,94,52,17,54,93排序，是否可以看做多关键字排序？ 12345678910111213141516171819202122232425# 基数排序 # 时间复杂度 O(kn)# 空间复杂度:O(k+n)# k表示数字位数def list_to_bucket(li, i): buckets = [[] for _ in range(10)] for val in li: digit = val // (10 ** i) % 10 buckets[digit].append(val) return bucketsdef bucket_to_list(buckets): li = [] for bucket in buckets: for val in bucket: li.append(val) return lidef radix_sort(li): max_val = max(li) i = 0 while 10 ** i &lt;= max_val: li = bucket_to_list(list_to_bucket(li, i)) i += 1 return li]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode的刷题(1-50)]]></title>
    <url>%2F2019%2F01%2F16%2FLeetCode%E7%9A%84%E5%88%B7%E9%A2%98-1-50%2F</url>
    <content type="text"></content>
      <categories>
        <category>LeetCode刷题之路</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础命令]]></title>
    <url>%2F2019%2F01%2F16%2Flinux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查看版本信息 cat /etc/redhat-release :查看版本信息 uname -r 查看内核版本号 uname -m 查看系统多少位 uname -a 查看内核全部信息 IP相关查看ip ip addr ifconfig ip详细信息 eth0 网卡的代号 lo 回环地址loopback inet IPv4的Ip地址 netmask 子网掩码 broadcast 广播地址 RX/TX 流量发/收情况 tx是发送（transport），rx是接收(receive) packets 数据包数 errors 数据包错误数 dropped 数据包有问题被丢弃的数量 collisions 数据包碰撞情况，数值太多代表网络状况差 ifup,ifdown 脚本命令,更简单的方式启动关闭网络 pup + 网卡名 ipdown + 网卡名 # 编辑网卡配置文件 vim /etc/sysconfig/network-scripts/ifcfg-eth0 # 修改配置参数 ONBOOT=yes 关闭防火墙 systemctl stop / start / restart firewalld 关闭/开启/重启 防火墙 systemctl disable firewalld 永久关闭防火墙 修改网络配置 systemctl restart network 重启服务 linux的目录结构 根目录 linux的文件系统 Ext3 : 是一款日志文件系统，能够在系统异常宕机时避免文件系统资料丢失，并能 自动修复数据的不一致与错误。 Etx4:Etx3的进阶版本,作为 RHEL 6 系统中的默认文件管理系统，它支持的存储容 量高达 1EB(1EB=1,073,741,824GB)，且能够有无限多的子目录。另外，Ext4 文件系统能够批量分配 block 块，从而极大地提高了读写效率。 XFS 是一种高性能的日志文件系统，而且是 RHEL 7 中默认的文件管理系统，它的优势在发生意外宕机后尤其明显，即可以快速地恢复可能被破坏的文件，而且强大的 日志功能只用花费极低的计算和存储性能。并且它最大可支持的存储容量为 18EB， 这几乎满足了所有需求。 查看linux的文件系统 cat /etc/fstab 创建文件夹 mkdir -p 文件名 查看目录 ls /目录名 stat 文件名:查看详细信息 创建文本 touch 文件名 改变当前的位置 cd /目录名 cd ~ :家目录 cd - :返回上一次的地址 打印当前目录 pwd 查看文本 cat -n 文件 :带行号 cat &gt;&gt; 文件 &lt;&lt; EOF …. EOF more 查看文件百分比 head 查看前10行 tail 查看后10行 tail -f 动态监听文件 linux快捷键 快捷键 说明 tab键 自动补全代码 ctrl + l 清理终端显示 clear / cls 清理终端显示 ctrl + c 终止操作 echo命令 echo $PATH :打印环境变量 特殊符号 “&gt;&gt;” 追加重定向 “&gt;” 清空重定向 “*” 通配符 复制 cp -r 递归,复制目录以及目录的子孙后代 cp -p 复制文件,且保持文件属性不变 cp -a :相当于-pdr 移动 mv 删除 rm -f 不需要提示,强制删除 rm -rf :全删 xargs命令 xargs命令是给其他命令传递参数的一个过滤器，擅长将标准输入数据转换成命令行参数，xargs能够处理管道或者stdin并将其转换成特定命令的参数。 xargs默认命令是echo，空格是默认定界符 查找命令 find 在哪里(目录) -type f -name ‘*.txt’ 找到所有txt文件 find / -name *.txt 管道命令 Linux提供的管道符“|”讲两条命令隔开，管道符左边命令的输出会作为管道符右边命令的输入。 命令格式:命令A|命令B grep(过滤) 文本搜素 grep ‘xxx’ 文件 -i:忽略大小写 -n:输出行号 -v:反向选择 sed(流编辑器) 用法 文本替换 sed -i ‘s/old/new/g’ 文件:把这文件里的全部old替换为new 删除空白行 sed -i ‘/^$/d’ 文件名 :把这个文件里全部的空行删除 删除5-10行内容 sed -i ‘5,10d’ 文件名 akw 语法: awk [option] ‘script’ var = value filename awk [options] -f scriptfile var=value filename 常用选项 -F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk -f scripfile 从脚本文件中读取awk命令 -m[fr] val 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 实例 # NR &gt; 行号 awk ‘NR==20,NR==30’ /tmp/oldboy.txt which命令 which命令用于查找并显示给定命令的绝对路径，环境变量PATH中保存了查找命令时需要遍历的目录。 which指令会在环境变量$PATH设置的目录里查找符合条件的文件。 也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 which pwd which python 别名alias 设置别名 alias rm = ‘echo “别用rm”‘ 取消设置:unalias rm seq(类似于for循环) seq -f ‘%03g’ 起始值 终止值 scp远程复制文件 语法: scp 【可选参数】 本地源文件 远程文件标记 参数 -r :递归复制整个目录 -v:详细方式输出 -q:不显示传输进度条 -C：允许压缩 事例 传输本地文件到远程地址 scp 本地文件 远程用户名@远程ip:远程文件夹/ 复制远程文件到本地 scp root@192.168.1.155:/home/oldboy.txt /tmp/oldboy.txt du命令 显示目录和文件大小 实例: du -sh 文件名 top top命令用于动态地件事进程活动与系统负载等信息 第一行 (uptime) 系统时间 主机运行时间 用户连接数(who) 系统1，5，15分钟的平均负载 第二行:进程信息 进程总数 正在运行的进程数 睡眠的进程数 停止的进程数 僵尸进程数 第三行:cpu信息 1.5 us：用户空间所占CPU百分比 0.9 sy：内核空间占用CPU百分比 0.0 ni：用户进程空间内改变过优先级的进程占用CPU百分比 97.5 id：空闲CPU百分比 0.2 wa：等待输入输出的CPU时间百分比 0.0 hi：硬件CPU中断占用百分比 0.0 si：软中断占用百分比 0.0 st：虚拟机占用百分比 第四行：内存信息（与第五行的信息类似与free命令） 8053444 total：物理内存总量 7779224 used：已使用的内存总量 274220 free：空闲的内存总量（free+used=total） 359212 buffers：用作内核缓存的内存量 第五行：swap信息 8265724 total：交换分区总量 33840 used：已使用的交换分区总量 8231884 free：空闲交换区总量 4358088 cached Mem：缓冲的交换区总量，内存中的内容被换出到交换区，然后又被换入到内存，但是使用过的交换区没有被覆盖，交换区的这些内容已存在于内存中的交换区的大小，相应的内存再次被换出时可不必再对交换区写入。 chattr 给文件加锁,只能写数据,无法删除 chattr +a 文件:给文件加锁 chattr -a 文件:给文件取消锁 lsattr 查看文件的隐藏属性 lsattr 文件名 linux时间同步 date +”%Y-%m-%d %T” 显示当前时间 同步系统时间和硬件时间，可以用hwclock命令 //以系统时间为基准，修改硬件时间 [root@oldboy_python ~ 10:29:07]#hwclock-w //以硬件时间为基准，修改系统时间 [root@oldboy_python ~ 10:29:21]#hwclock-s Ntp时间服务器 ntpdate -u ntp. aliyun. com:更新时间 wget命令 wget 参数 下载地址 开关机命令 reboot 命令用于重启机器 poweroff 用于关闭系统 用户管理和文件权限 用户管理 添加用户 useradd 用户名 :添加用户 passwd 用户名: 增加密码 切换用户 su - 用户名 su命令中间的-号很重要，意味着完全切换到新的用户，即环境变量信息也变更为新用户的信息 查看当前用户 whoami 退出用户 logout ctrl + d 创建用户组 grpupadd 组名 删除用户 -f 强制删除用户 -r 同事删除用户以及家目录 userdel -r 用户名 sudo命令 语法 sudo 【选项】【参数】 -b：在后台执行指令； -h：显示帮助； -H：将HOME环境变量设为新身份的HOME环境变量； -k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。 -l：列出目前用户可执行与无法执行的指令； -p：改变询问密码的提示符号； -s：执行指定的shell； -u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份； -v：延长密码有效期限5分钟； -V ：显示版本信息。 编辑/etc/sudoers文件,写入 用户名 ALL=(ALL) ALL # 允许chaoge在任何地方，执行任何命令 文件权限 图片 文件类型 - 一般文件 d 文件夹 l 软连接（快捷方式） b 块设备，存储媒体文件为主 c 代表键盘,鼠标等设备 文件权限 r read可读 w write写入，编辑 x executable 可以执行 查看用户权限命令 id 用户名 需改权限属性 修改属主 chown 属主名 文件名 修改属组 chgrp 属组名 文件名 文件权限 r —- &gt; 4 w ——&gt; 2 x ——-&gt;1 修改权限命令 chmod [身份][参数] [文件] u(user) +(添加) g(group) -(减去) o(other) =(赋值) a(all) 软连接 ln -s 目标文件 软连接名 PS1变量 inux命令提示符由PS1环境变量控制 参数 可以自行调整全局变量/etc/profile文件用于永久生效 PS1=’[\u@\h \W\t]\$’ \d 日期 \H 完整主机名 \h 主机名第一个名字 \t 时间24小时制HHMMSS\T 时间12小时制 \A 时间24小时制HHMM \u 当前用户账号名 \v BASH的版本\w 完整工作目录 \W 利用basename取得工作目录名 # 下达的第几个命令 \$ 提示字符，root为#，普通用户为$ PS1 &gt; 变量名 $PS1 &gt; 查看变量内容 PS1=新内容 重新赋值 在/etc/profile下增加 export PS1=[你要显示的格式,可永久修改] tar解压命令 语法 tar(选项)(参数) -A或–catenate：新增文件到以存在的备份文件； -B：设置区块大小； -c或–create：建立新的备份文件； -C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 -d：记录文件的差别； -x或–extract或–get：从备份文件中还原文件； -t或–list：列出备份文件的内容； -z或–gzip或–ungzip：通过gzip指令处理备份文件； -Z或–compress或–uncompress：通过compress指令处理备份文件； -f&lt;备份文件&gt;或–file=&lt;备份文件&gt;：指定备份文件； -v或–verbose：显示指令执行过程； -r：添加文件到已经压缩的文件； -u：添加改变了和现有的文件到已经存在的压缩文件； -j：支持bzip2解压文件； -v：显示操作过程； -l：文件系统边界设置； -k：保留原有文件不覆盖； -m：保留文件不被覆盖； -w：确认压缩文件的正确性； -p或–same-permissions：用原来的文件权限还原文件； -P或–absolute-names：文件名使用绝对名称，不移除文件名称前的“/”号； -N &lt;日期格式&gt; 或 –newer=&lt;日期时间&gt;：只将较指定日期更新的文件保存到备份文件里； –exclude=&lt;范本样式&gt;：排除符合范本样式的文件。 实例 tar -zxvf Python-3.7.0b3.tgz #解压 tar -czvf oldboy.txt.tar.gz oldboy.txt #压缩oldboy.txt 上述命令等于 tar -cvf oldboy.tar oldboy.txt gzip oldboy.tar tar -cf all_pic.tar *.jpg #压缩当前目录所有jpg结尾的文件 tar -xjf xx.tar.bz2 #解压缩bz2结尾的文件 gzip命令(压缩) 语法 -d或–decompress或—-uncompress：解开压缩文件； -f或——force：强行压缩文件。 -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； 实例 压缩当前目录所有文件为.gz文件 gzip * 把上例中每个压缩的文件解压，并列出详细的信息 gzip -dv * 显示压缩文件的信息，并不解压 gzip -l * 压缩一个tar备份文件，扩展名是tar.gz tar -cf my.tar my_first.py gzip -r my.tar netstat命令 netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 语法: netstat [选项] -t或–tcp：显示TCP传输协议的连线状况； -u或–udp：显示UDP传输协议的连线状况； -n或–numeric：直接使用ip地址，而不通过域名服务器； -l或–listening：显示监控中的服务器的Socket； -p或–programs：显示正在使用Socket的程序识别码和程序名称； -a或–all：显示所有连线中的Socket； ps命令 ps 命令用于查看系统中的进程状态，格式为“ps [参数]”。 参数 -a 显示所有进程 -u 用户以及其他详细信息 -x 显示没有控制终端的进程 Kill命令 kill命令用来删除执行中的程序或工作。kill可将指定的信息送至程序。 选项 -a：当处理当前进程时，不限制命令名和进程号的对应关系； -l &lt;信息编号&gt;：若不加&lt;信息编号&gt;选项，则-l参数会列出全部的信息名称； -p：指定kill 命令只打印相关进程的进程号，而不发送任何信号； -s &lt;信息名称或编号&gt;：指定要送出的信息； -u：指定用户。 9种信号 HUP 1 终端断线 INT 2 中断（同 Ctrl + C） QUIT 3 退出（同 Ctrl + \） TERM 15 终止 KILL 9 强制终止 CONT 18 继续（与STOP相反， fg/bg命令） STOP 19 暂停（同 Ctrl + Z） 实例 先用ps查找进程，然后用kill杀掉： ps -ef | grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.log root 3370 2822 0 16:21 pts/0 00:00:00 grep vim kill 3268 killall命令 通常来讲，复杂软件的服务程序会有多个进程协同为用户提供服务，如果逐个去结束这 些进程会比较麻烦，此时可以使用 killall 命令来批量结束某个服务程序带有的全部进程。 例子 例如nginx启动后有2个进程 killall nginx SELinux功能 大多数ssh连接不上虚拟机，都是因为防火墙和selinux阻挡了 永久关闭 1.修改配置文件，永久生效关闭selinux cp /etc/selinux/config /etc/selinux/config.bak #修改前备份 2.修改方式可以vim编辑,找到 # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled 3.用sed替换 sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/‘ /etc/selinux/config 4.检查状态 grep “SELINUX=disabled” /etc/selinux/config #出现结果即表示修改成功 临时关闭selinux(命令行修改，重启失效)： getenforce #获取selinux状态 #修改selinux状态 setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] 数字0 表示permissive，给出警告，不会阻止，等同disabled 数字1表示enforcing，表示开启 iptables防火墙 centos7默认已经使用firewall作为防火墙了 1.关闭防火墙 systemctl status firewalld #查看防火墙状态 systemctl stop firewalld #关闭防火墙 systemctl disable firewalld#关闭防火墙开机启动 systemctl is-enabled firewalld.service#检查防火墙是否启动 linux中文显示 1.修改配置文件/etc/locale.conf LANG=”zh_CN.UTF-8” 2.更改后查看系统语言变量:locale df 命令 语法: -h或–human-readable：以可读性较高的方式来显示信息； -k或–kilobytes：指定区块大小为1024字节； -T或–print-type：显示文件系统的类型； –help：显示帮助； –version：显示版本信息 tree tree命令以树状图列出目录的内容。 -a：显示所有文件和目录； -A：使用ASNI绘图字符显示树状图而非以ASCII字符组合； -C：在文件和目录清单加上色彩，便于区分各种类型； -d：先是目录名称而非内容； -D：列出文件或目录的更改时间； -f：在每个文件或目录之前，显示完整的相对路径名称； -F：在执行文件，目录，Socket，符号连接，管道名称名称，各自加上”*”，”/“，”@”，”|”号； -g：列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码； -i：不以阶梯状列出文件和目录名称； -l：&lt;范本样式&gt; 不显示符号范本样式的文件或目录名称； -l：如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录； -n：不在文件和目录清单加上色彩； -N：直接列出文件和目录名称，包括控制字符； -p：列出权限标示； -P：&lt;范本样式&gt; 只显示符合范本样式的文件和目录名称； -q：用“？”号取代控制字符，列出文件和目录名称； -s：列出文件和目录大小； -t：用文件和目录的更改时间排序； -u：列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码； -x：将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该目录予以排除在寻找范围外。 tree参数 DNS配置 配置文件 cat /etc/resolv.conf#dns 服务器地址 nameserver 223.5.5.5 nameserver 119.29.29.29 nslookup命令 nslookup命令是常用域名查询工具，就是查DNS信息用的命令。 例子:nslookup www.oldboyedu.com 计划任务crond服务 语法 -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称。 格式 分钟(0-59) 小时(0-23) 日期(1-31) 月份(1-12) 星期(0-6,0代表星期天) 命令 软件包管理 yum命令 参数 yum(选项)(参数) -h：显示帮助信息； -y：对所有的提问都回答“yes”； -c：指定配置文件； -q：安静模式； -v：详细模式； -d：设置调试等级（0-10）； -e：设置错误等级（0-10）； -R：设置yum处理一个命令的最大等待时间； -C：完全从缓存中运行，而不去下载或者更新任何头文件。 yum源配置 yum的目录 cd /etc/yum.repos.d/ https://opsx.alibaba.com/mirror 找到这个网站，然后找到centos7的帮助有第一和第二步操作 3.清空yum缓存并且生成新的yum缓存 yum clean all yum makecache 4.安装软件扩展源 yum install -y epel-release yum命令 yum repolist all 列出所有仓库 yum list all 列出仓库所有软件包 yum info 软件包名 查看软件包信息 yum install 软件包名 安装软件包 yum reinstall 软件包名 重新安装软件包 yum update 软件包名 升级软件包 yum remove 软件包名 移除软件包 yum clean all 清楚所有仓库缓存 yum check-update 检查可以更新的软件包 yum grouplist 查看系统中已安装的软件包 yum groupinstall 软件包组 安装软件包组]]></content>
      <categories>
        <category>linux的使用</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tornado框架]]></title>
    <url>%2F2019%2F01%2F15%2FTornado%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>tornado</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-celery的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2FDjango-celery%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>分布式任务</category>
      </categories>
      <tags>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[celery的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2Fcelery%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[celery是什么?​ celery是一个基于python实现的模块,模块可以帮助我们实现任务管理 什么情况下使用celery?一个请求的处理时间特别长,可以使用celery(例如:发送邮件,短信等) 安装celery1pip install celery 快速入门目录结构123456- celery_app -- __init__.py -- celeryconfig.py -- task1.py -- task2.py--demo.py init .py 1234from celery import Celeryapp = Celery('demo') # demo名称,可以是任意修改app.config_from_object('celery_app.celeryconfig') # 通过celery实例加载配置模块 celeryconfig.py配置文件 123456789101112131415161718192021222324252627282930from datetime import timedeltafrom celery.schedules import crontabBROKER_URL = 'redis://localhost:6379/1' # 设置broker存储的位置CELERY_RESULT_BACKEND = 'redis://localhost:6379/0' #设置backend的位置CELERY_TIMEZONE = 'Asia/Shanghai' # 设置时区# UTC# 导入指定的任务模块CELERY_IMPORTS = ( 'celery_app.task1', 'celery_app.task2')# 定时任务CELERYBEAT_SCHEDULE = &#123; 'task1':&#123; 'task':'celery_app.task1.add', 'schedule': timedelta(seconds=10), # 每10秒执行一次 'args':(2, 8) &#125;, 'task2':&#123; 'task':'celery_app.task2.multiply', 'schedule': crontab(hour=17,minute=27), # 每天的17点27分执行一次 'args':(4,5) &#125;&#125; task1.py 12345from celery_app import app@app.task # 设置一个处理任务的函数def add(x,y): return x + y task2.py 123456from celery_app import app@app.taskdef multiply(x , y): # 设置第二个 return x * y demo.py 12345678910111213141516171819# 发起任务from celery_app import task1from celery_app import task2# 第一种 参数:args是存放数据 eta=datetime(2018, 4, 11, 2, 32, 0):可以设置定时任务task1.add.apply_async() task1.add.delay(2,4)xx = task2.multiply.delay(4,5) # 第二种 直接传入参数# 获取结果from celery.result import AsyncResultfrom celery_app import appres = AsyncResult(id=xx.id,app=app)if res.ready(): # 判断结果是否返回 return res.get() # 返回的话把结果返回]]></content>
      <categories>
        <category>分布式任务</category>
      </categories>
      <tags>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zeroMQ的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2FzeroMQ%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>zeroMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2Fkafka%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAlchemy的使用]]></title>
    <url>%2F2019%2F01%2F15%2FSQLAlchemy%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是sqlalchemy?SQLAlchemy是Python编程语言下的一款ORM框架，该框架建立在数据库API之上，使用关系对象映射进行数据库操作，简言之便是：将对象转换成SQL，然后使用数据API执行SQL并获取执行结果。 连接数据库首先需要导入 sqlalchemy 库，然后建立数据库连接，这里使用 mysql。通过create_engine方法进行 12from sqlalchemy import create_engineengine = create_engine("mysql://root:@localhost:3306/webpy?charset=utf8",encoding="utf-8", echo=True) 基本使用1234567891011121314151617181920212223242526272829303132333435363738394041from sqlalchemy import Column, String, create_enginefrom sqlalchemy.orm import sessionmakerfrom sqlalchemy.ext.declarative import declarative_base# 创建对象的基类:Base = declarative_base()# 定义User对象:class User(Base): # 表的名字: __tablename__ = 'user' # 表的结构: id = Column(String(20), primary_key=True) name = Column(String(20))# 初始化数据库连接:engine = create_engine('mysql+mysqlconnector://root:password@localhost:3306/test')# 创建DBSession类型:DBSession = sessionmaker(bind=engine)# 创建session对象:session = DBSession()# 创建新User对象:new_user = User(id='5', name='Bob')# 添加到session:session.add(new_user)# 提交即保存到数据库:session.commit()# 关闭session:session.close()# 创建Session:session = DBSession()# 创建Query查询，filter是where条件，最后调用one()返回唯一行，如果调用all()则返回所有行:user = session.query(User).filter(User.id=='5').one()# 打印类型和对象的name属性:print('type:', type(user))print('name:', user.name)# 关闭Session:session.close() 引用: https://github.com/michaelliao/learn-python3/blob/master/samples/db/do_sqlalchemy.py]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sqlAlchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcache的使用]]></title>
    <url>%2F2019%2F01%2F15%2FMemcache%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是Memcached?Memcached 是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。 安装和参数Memcached的安装12345678wget http://memcached.org/latesttar -zxvf memcached-1.x.x.tar.gzcd memcached-1.x.x./configure &amp;&amp; make &amp;&amp; make test &amp;&amp; sudo make install PS：依赖libevent yum install libevent-devel apt-get install libevent-dev 启动Memcached12345678910memcached -d -m 10 -u root -l 10.211.55.4 -p 12000 -c 256 -P /tmp/memcached.pid 参数说明: -d 是启动一个守护进程 -m 是分配给Memcache使用的内存数量，单位是MB -u 是运行Memcache的用户 -l 是监听的服务器IP地址 -p 是设置Memcache监听的端口,最好是1024以上的端口 -c 选项是最大运行的并发连接数，默认是1024，按照你服务器的负载量来设定 -P 是设置保存Memcache的pid文件 python操作Memcached12# 下载pip install python-memcached 第一次操作12345678import memcachemc = memcache.Client(['127.0.0.1:11211'], debug=True)mc.set("foo", "bar")ret = mc.get('foo')print(ret)# debug = True 表示运行出现错误时，现实错误信息，上线后移除该参数。 天生支持集群python-memcached模块原生支持集群操作，其原理是在内存维护一个主机列表，且集群中主机的权重值和主机在列表中重复出现的次数成正比 1234567891011 主机 权重 1.1.1.1 1 1.1.1.2 2 1.1.1.3 1 那么在内存中主机列表为： host_list = ["1.1.1.1", "1.1.1.2", "1.1.1.2", "1.1.1.3", ]# 代码mc = memcache.Client([('1.1.1.1:12000', 1), ('1.1.1.2:12000', 2), ('1.1.1.3:12000', 1)], debug=True)mc.set('k1', 'v1') add添加一条键值对,如果已经存在key,重复执行add操作异常 12345import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)mc.add('k1', 'v1')# mc.add('k1', 'v2') # 报错，对已经存在的key重复添加，失败！！！ replacereplace修改某个key的值,如果key不存在则异常 12345import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)# 如果memcache中存在kkkk，则替换成功，否则异常mc.replace('kkkk','999') set和set_multiset 设置值一个键值对,如果key不存在,则创建,如果key存在,则修改 set_multi 设置多个键值对,如果key不存在,则创建,如果key存在,则修改 1234import memcachemc = memcache.Client(['10.211.55.4:11211'], debug=True)mc.set('key0', 'wupeiqi')mc.set_multi(&#123;'key1': 'val1', 'key2': 'val2'&#125;) delete 和 delete_multidelete 在Memcached中删除指定一个键值对 delete_multi 在Memcached中删除指定的多个键值对 123456import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True) mc.delete('key0')mc.delete_multi(['key1', 'key2']) get 和 get_multiget 获取一个键值对 get_multi 获取多个键值对 1234import memcachemc = memcache.Client(['10.211.55.4:11211'], debug=True)val = mc.get('key0')item_dict = mc.get_multi(["key1", "key2", "key3"]) append 和 prependappend 修改指定key的值,在该值后面追加内容 prepend 修改指定key的值,在该值前面插入内容 12345678910import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)# k1 = "v1" mc.append('k1', 'after')# k1 = "v1after" mc.prepend('k1', 'before')# k1 = "beforev1after" decr和incrincr 自增,将Memcached中的某一个值增加N(N默认是1) decr 自减,将Memcached中的某一个值减少N(N默认是1) 12345678910111213141516import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)mc.set('k1', '777') mc.incr('k1')# k1 = 778 mc.incr('k1', 10)# k1 = 788 mc.decr('k1')# k1 = 787 mc.decr('k1', 10)# k1 = 777 gets 和 cas如商城商品剩余个数，假设改值保存在memcache中，product_count = 900A用户刷新页面从memcache中读取到product_count = 900B用户刷新页面从memcache中读取到product_count = 900 如果A、B用户均购买商品 A用户修改商品剩余个数 product_count＝899B用户修改商品剩余个数 product_count＝899 如此一来缓存内的数据便不在正确，两个用户购买商品后，商品剩余还是 899如果使用python的set和get来操作以上过程，那么程序就会如上述所示情况！ 如果想要避免此情况的发生，只要使用 gets 和 cas 即可，如： 1234567import memcachemc = memcache.Client(['10.211.55.4:12000'], debug=True, cache_cas=True) v = mc.gets('product_count')# ...# 如果有人在gets之后和cas之前修改了product_count，那么，下面的设置将会执行失败，剖出异常，从而避免非正常数据的产生mc.cas('product_count', "899") ​ 本质上每次执行gets时，会从memcache中获取一个自增的数字，通过cas去修改gets的值时，会携带之前获取的自增值和memcache中的自增值进行比较，如果相等，则可以提交，如果不想等，那表示在gets和cas执行之间，又有其他人执行了gets（获取了缓冲的指定值）， 如此一来有可能出现非正常数据，则不允许修改]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mangoDB基础]]></title>
    <url>%2F2019%2F01%2F14%2FmangoDB%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[数据库中的用法MangoDB的对应关系引用了不存在的对象来创建改对象 1234database ------&gt; Databasetable -------&gt; Collection字段 --------&gt; Fieldrow ---------&gt; Document mangoDB增删改查123456789101112131415161718增: 官方不推荐写法: db.users.insert([&#123;&#125;]) db.users.insert(&#123;&#125;) 官方支持写法 db.users.insertMany([&#123;'name':'ccc','age':88&#125;,&#123;'name':'ddd','age':88&#125;]) db.users.insertOne(&#123;name:"xxx",age:"73"&#125;)查: db.users.find(&#123;age:73,name:"xxx"&#125;) db.users.findOne(&#123;age:73&#125;)改：MongoDB修改器 $set $unset:删除字段的 db.users.updateOne(&#123;age:73&#125;,&#123;$set:&#123;age:74&#125;&#125;) db.users.updateMany(&#123;age:74&#125;,&#123;$set:&#123;age:73&#125;&#125;) 删: db.users.deleteOne(&#123;age:"84"&#125;) db.users.deleteMany(&#123;age:"84"&#125;) MongoDB的数据类型12345678910Object ID ：Documents 自生成的 _idString： 字符串，必须是utf-8Boolean：布尔值，true 或者false (这里有坑哦~在Python中 True False 首字母大写)Integer：整数 (Int32 Int64 你们就知道有个Int就行了,一般我们用Int32)Double：浮点数 (没有float类型,所有小数都是Double)Arrays：数组或者列表，多个值存储到一个键 (list哦,大Python中的List哦)Object：如果你学过Python的话,那么这个概念特别好理解,就是Python中的字典,这个数据类型就是字典Null：空数据类型 , 一个特殊的概念,None NullTimestamp：时间戳Date：存储当前日期或时间unix时间格式 (我们一般不用这个Date类型,时间戳可以秒杀一切时间类型) $关键字12345678910111213141516171819202122232425修改器 $set : 强制覆盖 $unset : 删除字段 $inc ：引用自增 $inc:&#123;age:-1&#125; $push append(7) db.sss.updateOne(&#123;name:"xxx"&#125;,&#123;$push:&#123;hobby_1:7&#125;&#125;) $pull remove(1) db.sss.updateOne(&#123;name:"xxx"&#125;,&#123;$pull:&#123;hobby_1:1&#125;&#125;) $pop pop() db.sss.updateOne(&#123;name:"xxx"&#125;,&#123;$pop:&#123;hobby_1:1/-1&#125;&#125;) 1删除最后一个,-1代表删除第一个 查询关键： $or $or:[&#123;age:1&#125;,&#123;name:2&#125;] $all &#123;u_list:&#123;$all:[321,123]&#125;&#125; $in &#123;age:&#123;$in:[10,15]&#125;&#125; 数学比较符： $lt &#123;age:&#123;$gt:10&#125;&#125; $lte $gt $gte $eq : $ne &#123;age:&#123;$ne:15&#125;&#125; 4. $ (&#123;name:"xxx","hobby.name":"个人计算机"&#125;,&#123;$set:&#123;"hobby.$.name":"PC"&#125;&#125;) skip limit sort12345sort: sort(&#123; age:1 / -1&#125;) -1:倒序 1:正序 skip: skip(2) 跳过两条limit： limit(2) 选取两条优先级: 1.sort 2.skip 3.limit python中使用MangoDB连接MongoDBClient12import pymongoclient = pymongo.MongoClient(host='localhost', port=27017) 获取数据库12db = Client.test_databasedb = Client['test_database'] 获取CollectionCollection是存储在MongoDB中的一组文件，同获取database一样，你可以用点取属性的方式或者字典的方法获取： 12collection = db.test_collectioncollection = db['test_collection'] 其他操作和上面一样]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MangoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis进阶]]></title>
    <url>%2F2019%2F01%2F14%2Fredis%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[什么是redisredis是一个基于内存的高性能key-value数据库 2.redis的特点Redis本质是一个key-value类型的数据库,就像memcached,整个数据库统统加载在内存中进行操作,定期通过异步把数据库数据push到硬盘上进行保存,因为是纯内存操作所以redis的性能非常出色,每秒可以处理10万次读写操作,是已知性能最快的key-value DB Redis的出色之处不仅仅只有他的性能,Redis最大的魅力是支持多种数据结构,此外单个value的最大限制是1GB,不像memcached只能保存1MB的数据,因此redis可以用来实现很多有用的功能,比如:用他的List来做FIFO双向链表实现一个轻量级的高性能消息队列服务,用他的set可以做高性能的tag系统等等,另外Redis也可以对存入的key-value设置expire(过期)时间,因此也可以当做一个加强版的memcached来用. Redis主要缺点是数据库容量受物理内存限制,不能做海量数据的高性能读写,因此它只适合在较小数据量的高性能操作和运算上 PS—–&gt;memcached:是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。 3.Redis支持的数据类型Redis通过key-value的单值不同类型区分 strings Lists sets sorted set hashes 4.为什么redis需要把所有数据放到内存中redis为了达到最快的读写速度将数据都读到内存中,并通过异步的方式将数据写入磁盘,所以redis具有快速和数据持久化的特性,如果不将数据放在内存中,磁盘I/O速度会影响redis的性能, 如果设置最大使用的内存,则数据已有记录达到内存限值后不能继续插入新值 5.Redis是单进程单线程的redis利用队列技术将并发访问变成为串行访问,消除了传统数据库串行控制开销 6.虚拟内存当你的key很小而value很大时,使用vm的效果会比较好,因为这样节约内存比较大 当你的key不小时,可以考虑一些非常方法将很大的key变成value,比如你可以将key-value变成一个value vm-max-threads这个参数,可以设置访问swap文件的线程数,设置最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证. 7.分布式redis支持主从的模式,原则:master(控制)会将数据同步到slave,而slave不会讲数据同步到master,slave启动时会连接master来同步数据 这是一个典型的分布式读写分离模型,我们可以利用master来插入数据,slave提供检索服务,这样可以有效减少单个机器的并发访问数量 8.读写分离模型通过增加slave DB的数量,读的性能可以线性增长,为了避免master DB的单点故障,集群一般都会采用两台master DB做双机热备所以整个集群的读和写的可用性都非常高 读写分离的缺陷:不管master还是slave,每个节点都必须保存完整的数据,如果在数据量很大的时候,集群的扩展能力还是受限于每个节点 的存储能力,而且对于write-intensive类型的应用,读写分离的架构并不合适 9.数据分片模型为了解决读写分离模型的缺陷,可以将数据分片模型应用进来 可以将每个节点都看成独立的master,然后通过业务实现数据分片 结合上面两种模型,可以将每个master设计由一个master和多个slave组成的模型 10.Redis的回收策略 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 11.使用redis有哪些好处 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 支持丰富数据类型，支持string，list，set，sorted set，hash 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 12.redis相比memcached有哪些优势？ memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 redis的速度比memcached快很多 redis可以持久化其数据 13.redis常见性能问题和解决方案： Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 尽量避免在压力很大的主库上增加从库 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3… 这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变 14.MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。详情见 redis的回收策略 15.redis常见的性能问题有哪些?如何解决 Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 16.redis适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢? Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 、Redis支持数据的备份，即master-slave模式的数据备份。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 17、会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 18、全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 19、队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 20，排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES 21、发布/订阅最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础]]></title>
    <url>%2F2019%2F01%2F14%2Fredis%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[redis的数据类型 string(字符串) Hash(哈希/字典) List(数组/列表) 无序集合 有序集合 安装1pip install redi 操作模式redis-py提供两个类Redis和StrictRedis用于实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令，Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。 1234import redisr = redis.Redis(host='10.211.55.4', port=6379)r.set('foo', 'Bar')print r.get('foo') 连接池redis-py使用connection pool来管理对一个redis server的所有连接，避免每次建立、释放连接的开销。默认，每个Redis实例都会维护一个自己的连接池。可以直接建立一个连接池，然后作为参数Redis，这样就可以实现多个Redis实例共享一个连接池。 12345import redispool = redis.ConnectionPool(host='10.211.55.4', port=6379)r = redis.Redis(connection_pool=pool)r.set('foo', 'Bar')print r.get('foo') string的基本操作set(name,value,ex=None,px=None,nx=False,xx=False) 123456在Redis中设置值，默认，不存在则创建，存在则修改参数： ex，过期时间（秒） px，过期时间（毫秒） nx，如果设置为True，则只有name不存在时，当前set操作才执行 xx，如果设置为True，则只有name存在时，岗前set操作才执行 setnx(name, value)设置值，只有name不存在时，执行设置操作（添加） setex(name, value, time) :time，过期时间（数字秒 或 timedelta对象） psetex(name, time_ms, value) :time_ms，过期时间（数字毫秒 或 timedelta对象） mset(*args, **kwargs) 12345批量设置值如： mset(k1='v1', k2='v2') 或 mget(&#123;'k1': 'v1', 'k2': 'v2'&#125;) get(name):获取值 mget(keys, *args) 12345批量获取如： mget('ylr', 'wupeiqi') 或 r.mget(['ylr', 'wupeiqi']) getset(name, value) :设置新值并获取原来的值 getrange(key, start, end) : 12345# 获取子序列（根据字节获取，非字符）# 参数： # name，Redis 的 name # start，起始位置（字节） # end，结束位置（字节） setrange(name, offset, value) 1234修改字符串内容，从指定字符串索引开始向后替换（新值太长时，则向后添加）参数： # offset，字符串的索引，字节（一个汉字三个字节） # value，要设置的值 setbit(name, offset, value) 12345678910111213141516171819202122232425 对name对应值的二进制表示的位进行操作 参数： # name，redis的name # offset，位的索引（将值变换成二进制后再进行索引） # value，值只能是 1 或 0 注：如果在Redis中有一个对应： n1 = "foo"， 那么字符串foo的二进制表示为：01100110 01101111 01101111 所以，如果执行 setbit('n1', 7, 1)，则就会将第7位设置为1， 那么最终二进制则变成 01100111 01101111 01101111，即："goo" 扩展，转换二进制表示： # source = "郝起瀚" source = "foo" for i in source: num = ord(i) print bin(num).replace('b','') 特别的，如果source是汉字 "郝起瀚"怎么办？ 答：对于utf-8，每一个汉字占 3 个字节，那么 "武沛齐" 则有 9个字节 对于汉字，for循环时候会按照 字节 迭代，那么在迭代时，将每一个字节转换 十进制数，然后再将十进制数转换成二进制 11100110 10101101 10100110 11100110 10110010 10011011 11101001 10111101 10010000 getbit(name, offset) 1获取name对应的值的二进制表示中的某位的值 （0或1） bitcount(key, start=None, end=None) 12345获取name对应的值的二进制表示中 1 的个数参数： # key，Redis的name # start，位起始位置 # end，位结束位置 bitop(operation, dest, *keys) 12345678910获取多个值，并将值做位运算，将最后的结果保存至新的name对应的值 参数： operation,AND（并） 、 OR（或） 、 NOT（非） 、 XOR（异或） dest, 新的Redis的name *keys,要查找的Redis的name 如： bitop("AND", 'new_name', 'n1', 'n2', 'n3') 获取Redis中n1,n2,n3对应的值，然后讲所有的值做位运算（求并集），然后将结果保存 new_name 对应的值中 strlen(name) 1返回name对应值的字节长度（一个汉字3个字节） incr(self, name, amount=1) 1234567 自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。 参数： # name,Redis的name # amount,自增数（必须是整数） 注：同incrby incrbyfloat(self, name, amount=1.0) 12345自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。 参数： name,Redis的name amount,自增数（浮点型） decr(self, name, amount=1) 12345自减 name对应的值，当name不存在时，则创建name＝amount，否则，则自减。参数： name,Redis的name amount,自减数（整数） append(key, value) 12345在redis name对应的值后面追加内容 参数： key, redis的name value, 要追加的字符串 Hash操作hset(name,key,value) 123456789name对应的hash中设置一个键值对（不存在，则创建；否则，修改） 参数： name，redis的name key，name对应的hash中的key value，name对应的hash中的value 注： hsetnx(name, key, value),当name对应的hash中不存在当前key时则创建（相当于添加） hmset(name, mapping) 1234567在name对应的hash中批量设置键值对 参数： name，redis的name mapping，字典，如：&#123;'k1':'v1', 'k2': 'v2'&#125;如： r.hmset('xx', &#123;'k1':'v1', 'k2': 'v2'&#125;) hget(name,key) 1在name对应的hash中获取根据key获取value hmget(name, keys, *args) 1234567891011在name对应的hash中获取多个key的值 参数： name，reids对应的name keys，要获取key集合，如：['k1', 'k2', 'k3'] *args，要获取的key，如：k1,k2,k3 如： r.mget('xx', ['k1', 'k2']) 或 print r.hmget('xx', 'k1', 'k2') hgetall(name) 1获取name对应hash的所有键值 hlen(name) 1获取name对应的hash中键值对的个数 hkeys(name) 1获取name对应的hash中所有的key的值 hvals(name) 1获取name对应的hash中所有的value的值 hexists(name, key) 1检查name对应的hash是否存在当前传入的key hdel(name,*keys) 1将name对应的hash中指定key的键值对删除 hincrby(name, key, amount=1) 12345自增name对应的hash中的指定key的值，不存在则创建key=amount参数： name，redis中的name key， hash对应的key amount，自增数（整数） hincrbyfloat(name, key, amount=1.0) 1234567自增name对应的hash中的指定key的值，不存在则创建key=amount 参数： name，redis中的name key， hash对应的key amount，自增数（浮点数）自增name对应的hash中的指定key的值，不存在则创建key=amount hscan(name, cursor=0, match=None, count=None) 1234567891011增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，从而放置内存被撑爆 参数： name，redis的name cursor，游标（基于游标分批取获取数据） match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 如： 第一次：cursor1, data1 = r.hscan('xx', cursor=0, match=None, count=None) 第二次：cursor2, data1 = r.hscan('xx', cursor=cursor1, match=None, count=None) hscan_iter(name, match=None, count=None) 123456789利用yield封装hscan创建生成器，实现分批去redis中获取数据 参数： match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 如： for item in r.hscan_iter('xx'): print item List操作redis中的List在在内存中按照一个name对应一个List来存储。 lpush(name,values) 12345678在name对应的list中添加元素，每个新的元素都添加到列表的最左边 如： r.lpush('oo', 11,22,33) 保存顺序为: 33,22,11 扩展： rpush(name, values) 表示从右向左操作 lpushx(name,value) 1234在name对应的list中添加元素，只有name已经存在时，值添加到列表的最左边 更多： rpushx(name, value) 表示从右向左操作 llen(name) 1name对应的list元素的个数 linsert(name, where, refvalue, value)) 1234567在name对应的列表的某一个值前或后插入一个新值 参数： name，redis的name where，BEFORE或AFTER refvalue，标杆值，即：在它前后插入数据 value，要插入的数据 r.lset(name, index, value) 123456对name对应的list中的某一个索引位置重新赋值 参数： name，redis的name index，list的索引位置 value，要设置的值 r.lrem(name, value, num) 12345678在name对应的list中删除指定的值 参数： name，redis的name value，要删除的值 num， num=0，删除列表中所有的指定值； num=2,从前到后，删除2个； num=-2,从后向前，删除2个 lpop(name) 1234在name对应的列表的左侧获取第一个元素并在列表中移除，返回值则是第一个元素 更多： rpop(name) 表示从右向左操作 lindex(name, index) 1在name对应的列表中根据索引获取列表元素 lrange(name, start, end) 12345在name对应的列表分片获取数据 参数： name，redis的name start，索引的起始位置 end，索引结束位置 ltrim(name, start, end) 12345在name对应的列表中移除没有在start-end索引之间的值参数： name，redis的name start，索引的起始位置 end，索引结束位置 rpoplpush(src, dst) 1234从一个列表取出最右边的元素，同时将其添加至另一个列表的最左边 参数： src，要取数据的列表的name dst，要添加数据的列表的name blpop(keys, timeout) 12345将多个列表排列，按照从左到右去pop对应列表的元素 参数： keys，redis的name的集合 timeout，超时时间，当元素所有列表的元素获取完之后，阻塞等待列表内有数据的时间（秒）, 0 表示永远阻塞 brpoplpush(src, dst, timeout=0) 123456从一个列表的右侧移除一个元素并将其添加到另一个列表的左侧 参数： src，取出并要移除元素的列表对应的name dst，要插入元素的列表对应的name timeout，当src对应的列表中没有数据时，阻塞等待其有数据的超时时间（秒），0 表示永远阻塞 自定义增量迭代 123456789101112131415161718由于redis类库中没有提供对列表元素的增量迭代，如果想要循环name对应的列表的所有元素，那么就需要： 1、获取name对应的所有列表 2、循环列表但是，如果列表非常大，那么就有可能在第一步时就将程序的内容撑爆，所有有必要自定义一个增量迭代的功能： def list_iter(name): """ 自定义redis列表增量迭代 :param name: redis中的name，即：迭代name对应的列表 :return: yield 返回 列表元素 """ list_count = r.llen(name) for index in xrange(list_count): yield r.lindex(name, index) 使用for item in list_iter('pp'): print item Set操作Set集合就是不允许重复的列表 sadd(name,values) 1name对应的集合中添加元素 scard(name) 1获取name对应的集合中元素个数 sdiff(keys, *args) 1在第一个name对应的集合中且不在其他name对应的集合的元素集合 sdiffstore(dest, keys, *args) 1获取第一个name对应的集合中且不在其他name对应的集合，再将其新加入到dest对应的集合中 sinter(keys, *args) 1获取多一个name对应集合的并集 sinterstore(dest, keys, *args) 1获取多一个name对应集合的并集，再讲其加入到dest对应的集合中 sismember(name, value) 1检查value是否是name对应的集合的成员 smembers(name) 1获取name对应的集合的所有成员 smove(src, dst, value) 1将某个成员从一个集合中移动到另外一个集合 spop(name) 1从集合的右侧（尾部）移除一个成员，并将其返回 srandmember(name, numbers) 1从name对应的集合中随机获取 numbers 个元素 srem(name, values) 1在name对应的集合中删除某些值 sunion(keys, *args) 1获取多一个name对应的集合的并集 sunionstore(dest,keys, *args) 1获取多一个name对应的集合的并集，并将结果保存到dest对应的集合中 sscan(name, cursor=0, match=None, count=None) sscan_iter(name, match=None, count=None) 1同字符串的操作，用于增量迭代分批获取元素，避免内存消耗太大 有序集合在集合的基础上，为每元素排序；元素的排序需要根据另外一个值来进行比较，所以，对于有序集合，每一个元素有两个值，即：值和分数，分数专门用来做排序。 zadd(name,*args,**kwargs) 12345在name对应的有序集合中添加元素 如： zadd('zz', 'n1', 1, 'n2', 2) 或 zadd('zz', n1=11, n2=22) zcard(name) 1获取name对应的有序集合元素的数量 zcount(name, min, max) 1获取name对应的有序集合中分数 在 [min,max] 之间的个数 zincrby(name, value, amount) 1自增name对应的有序集合的 name 对应的分数 r.zrange( name, start, end, desc=False, withscores=False, score_cast_func=float) 123456789101112131415161718按照索引范围获取name对应的有序集合的元素 参数： name，redis的name start，有序集合索引起始位置（非分数） end，有序集合索引结束位置（非分数） desc，排序规则，默认按照分数从小到大排序 withscores，是否获取元素的分数，默认只获取元素的值 score_cast_func，对分数进行数据转换的函数 更多： 从大到小排序 zrevrange(name, start, end, withscores=False, score_cast_func=float) 按照分数范围获取name对应的有序集合的元素 zrangebyscore(name, min, max, start=None, num=None, withscores=False, score_cast_func=float) 从大到小排序 zrevrangebyscore(name, max, min, start=None, num=None, withscores=False, score_cast_func=float) zrank(name, value) 1234获取某个值在 name对应的有序集合中的排行（从 0 开始） 更多： # zrevrank(name, value)，从大到小排序 zrangebylex(name, min, max, start=None, num=None) 1234567891011121314151617当有序集合的所有成员都具有相同的分值时，有序集合的元素会根据成员的 值 （lexicographical ordering）来进行排序，而这个命令则可以返回给定的有序集合键 key 中， 元素的值介于 min 和 max 之间的成员对集合中的每个成员进行逐个字节的对比（byte-by-byte compare）， 并按照从低到高的顺序， 返回排序后的集合成员。 如果两个字符串有一部分内容是相同的话， 那么命令会认为较长的字符串比较短的字符串要大 参数： name，redis的name min，左区间（值）。 + 表示正无限； - 表示负无限； ( 表示开区间； [ 则表示闭区间 min，右区间（值） start，对结果进行分片处理，索引位置 num，对结果进行分片处理，索引后面的num个元素 如： # ZADD myzset 0 aa 0 ba 0 ca 0 da 0 ea 0 fa 0 ga # r.zrangebylex('myzset', "-", "[ca") 结果为：['aa', 'ba', 'ca'] 更多： 从大到小排序 zrevrangebylex(name, max, min, start=None, num=None) zrem(name, values) 12删除name对应的有序集合中值是values的成员如：zrem('zz', ['s1', 's2']) zremrangebyrank(name, min, max) 1根据排行范围删除 zremrangebyscore(name, min, max) 1根据分数范围删除 zremrangebylex(name, min, max) 1根据值返回删除 zscore(name, value) 1获取name对应有序集合中 value 对应的分数 zinterstore(dest, keys, aggregate=None) 12获取两个有序集合的交集，如果遇到相同值不同分数，则按照aggregate进行操作aggregate的值为: SUM MIN MAX zunionstore(dest, keys, aggregate=None) 12获取两个有序集合的并集，如果遇到相同值不同分数，则按照aggregate进行操作aggregate的值为: SUM MIN MAX zscan(name, cursor=0, match=None, count=None, score_cast_func=float) zscan_iter(name, match=None, count=None,score_cast_func=float) 1同字符串相似，相较于字符串新增score_cast_func，用来对分数进行操作 其他常用操作delete(*names) 1根据删除redis中的任意数据类型 exists(name) 1检测redis的name是否存在 keys(pattern=’*’) 1234567根据模型获取redis的name 更多： KEYS * 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 KEYS h*llo 匹配 hllo 和 heeeeello 等。 KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo expire(name ,time) 1为某个redis的某个name设置超时时间 rename(src, dst) 1对redis的name重命名为 move(name, db)) 1将redis的某个值移动到指定的db下 randomkey() 1随机获取一个redis的name（不删除） type(name) 1获取name对应值的类型 scan(cursor=0, match=None, count=None) scan_iter(match=None, count=None) 1同字符串操作，用于增量迭代获取key 管道redis-py默认在执行每次请求都会创建（连接池申请连接）和断开（归还连接池）一次连接操作，如果想要在一次请求中指定多个命令，则可以使用pipline实现一次请求指定多个命令，并且默认情况下一次pipline 是原子性操作。 12345678910111213import redis pool = redis.ConnectionPool(host='10.211.55.4', port=6379) r = redis.Redis(connection_pool=pool) # pipe = r.pipeline(transaction=False)pipe = r.pipeline(transaction=True)pipe.multi()pipe.set('name', 'alex')pipe.set('role', 'sb') pipe.execute() 发布订阅12345678910111213141516171819import redisclass RedisHelper: def __init__(self): self.__conn = redis.Redis(host='10.211.55.4') self.chan_sub = 'fm104.5' self.chan_pub = 'fm104.5' def public(self, msg): self.__conn.publish(self.chan_pub, msg) return True def subscribe(self): pub = self.__conn.pubsub() pub.subscribe(self.chan_sub) pub.parse_response() return pub 订阅者 12345678from monitor.RedisHelper import RedisHelper obj = RedisHelper()redis_sub = obj.subscribe() while True: msg= redis_sub.parse_response() print msg 发布者： 1234from monitor.RedisHelper import RedisHelper obj = RedisHelper()obj.public('hello') sentinel(哨兵)redis重的sentinel主要用于在redis主从复制中，如果master顾上，则自动将slave替换成master 12345678910111213141516171819202122232425from redis.sentinel import Sentinel 连接哨兵服务器(主机名也可以用域名)sentinel = Sentinel([('10.211.55.20', 26379), ('10.211.55.20', 26380), ], socket_timeout=0.5) 获取主服务器地址 master = sentinel.discover_master('mymaster') print(master) 获取从服务器地址slave = sentinel.discover_slaves('mymaster') print(slave)获取主服务器进行写入 master = sentinel.master_for('mymaster') master.set('foo', 'bar') 获取从服务器进行读取（默认是round-roubin） slave = sentinel.slave_for('mymaster', password='redis_auth_pass') r_ret = slave.get('foo') print(r_ret)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql进阶]]></title>
    <url>%2F2019%2F01%2F14%2Fmysql%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[存储过程一.存储过程的定义存储过程是把一段代码封装起来，当要执行这一段代码的时候，可以通过调用该存储过程来实现（经过第一次编译后再次调用不需要再次编译，比一个个执行sql语句效率高） 二.存储过程的优点 通常存储过程有助于提高应用程序的性能。当创建，存储过程被编译之后，就存储在数据库中。 但是，MySQL实现的存储过程略有不同。 MySQL存储过程按需编译。 在编译存储过程之后，MySQL将其放入缓存中。 MySQL为每个连接维护自己的存储过程高速缓存。 如果应用程序在单个连接中多次使用存储过程，则使用编译版本，否则存储过程的工作方式类似于查询。 存储过程有助于减少应用程序和数据库服务器之间的流量，因为应用程序不必发送多个冗长的SQL语句，而只能发送存储过程的名称和参数。 存储的程序对任何应用程序都是可重用的和透明的。 存储过程将数据库接口暴露给所有应用程序，以便开发人员不必开发存储过程中已支持的功能。 存储的程序是安全的。 数据库管理员可以向访问数据库中存储过程的应用程序授予适当的权限，而不向基础数据库表提供任何权限。 三.存储过程的缺点 如果使用大量存储过程，那么使用这些存储过程的每个连接的内存使用量将会大大增加。 此外，如果您在存储过程中过度使用大量逻辑操作，则CPU使用率也会增加，因为数据库服务器的设计不当于逻辑运算 存储过程的构造使得开发具有复杂业务逻辑的存储过程变得更加困难。 很难调试存储过程。只有少数数据库管理系统允许您调试存储过程。不幸的是，MySQL不提供调试存储过程的功能。 开发和维护存储过程并不容易。开发和维护存储过程通常需要一个不是所有应用程序开发人员拥有的专业技能。这可能会导致应用程序开发和维护阶段的问题。 四.一个简单的mysql存储过程示例123456delimiter // create procedure b1() begin select * from blog; end //delimiter ; 解释: 第一个命令是delimiter //，它与存储过程语法无关。 delimter语句将标准分隔符 - 分号(;)更改为：//。 在这种情况下，分隔符从分号(;)更改为双斜杠//。为什么我们必须更改分隔符？ 因为我们想将存储过程作为整体传递给服务器，而不是让mysql工具一次解释每个语句。 在END关键字之后，使用分隔符//来指示存储过程的结束。 最后一个命令(DELIMITER;)将分隔符更改回分号(;)。 .使用create procedure语句创建一个新的存储过程。在create procedure语句之后指定存储过程的名称。在这个示例中，存储过程的名称为：b1，并把括号放在存储过程的名字之后。 begin和end之间的部分称为存储过程的主体。将声明性SQL语句放在主体中以处理业务逻辑。 在这个存储过程中，我们使用一个简单的select语句来查询blog表中的数据。 123456mysql中调用存储过程 call b1()在python中基于pymysql调用cursor.callproc('b1') print(cursor.fetchall()) 五.声明变量要在存储过程中声明变量，可以使用delclare语句，如下 1DECLARE variable_name datatype(size) DEFAULT default_value; 在DECLARE关键字后面要指定变量名。变量名必须遵循MySQL表列名称的命名规则 指定变量的数据类型及其大小。变量可以有任何MySQL数据类型，如INT，VARCHAR，DATETIME等。 当声明一个变量时，它的初始值为NULL。但是可以使用DEFAULT关键字为变量分配默认值 1234567891011delimiter // create procedure b2() begin DECLARE n int DEFAULT 1; set n = 5; select * from blog where id = n; end //delimiter ;# mysql中调用存储过程call b2(); 六.存储过程传参在现实应用中，开发的存储过程几乎都需要参数。这些参数使存储过程更加灵活和有用。 在MySQL中，参数有三种模式：IN，OUT或INOUT。 IN - 是默认模式。在存储过程中定义IN参数时，调用程序必须将参数传递给存储过程。 另外，IN参数的值被保护。这意味着即使在存储过程中更改了IN参数的值，在存储过程结束后仍保留其原始值。换句话说，存储过程只使用IN参数的副本。 OUT - 可以在存储过程中更改OUT参数的值，并将其更改后新值传递回调用程序。请注意，存储过程在启动时无法访问OUT参数的初始值。 INOUT - INOUT参数是IN和OUT参数的组合。这意味着调用程序可以传递参数，并且存储过程可以修改INOUT参数并将新值传递回调用程序。 在存储过程中定义参数的语法如下 1MODE param_name param_type(param_size) 根据存储过程中参数的目的，MODE可以是IN，OUT或INOUT。 param_name是参数的名称。参数的名称必须遵循MySQL中列名的命名规则。 在参数名之后是它的数据类型和大小。和变量一样，参数的数据类型可以是任何有效的MySQL数据类型 如果存储过程有多个参数，则每个参数由逗号(,)分隔。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 1.indelimiter // create procedure b3( in blogName varchar(30) ) begin select * from blog where NAME = blogName; end //delimiter ;#mysql中调用存储过程call b3('第5篇');#python中调用存储过程cursor.callproc('b3',args = ('第5篇')); # 2.outdelimiter // create procedure b4( in year int, out count int ) begin SELECT COUNT(1) into count FROM blog GROUP BY DATE_FORMAT(sub_time,'%Y') having max(DATE_FORMAT(sub_time,'%Y')) = year ; set count = 6; end //delimiter ;call b4(2016,@count);select @count; #out只能当返回值 # 3.inoutdelimiter // create procedure b5( inout n1 int ) begin select * from blog where id &gt; n1; end //delimiter ;#mysql中调用set @n = 3;call b5(@n);select @n;#在python中基于pymysql调用cursor.callproc('b5',(4))print(cursor.fetchall()) #查询select的查询结果cursor.execute('select @n1') print(cursor.fetchall())# inout:既可以传入又可以返回 事务事务用于将某些操作的多个sql作为原子性操作,一旦有某一个出现错误,即可回滚到原来的状态,从而保证数据库的完整性 事务的四大特性 原子性:是指事务是一个不可分割的整体,事务中的操作要么就全部发生,要么都不成功 一致性:事务处理前后数据的完整性必须保持一致,完整性是指一个数据在某个时间点完全满足数据库中的约束要求 隔离性:是指多个用户访问一个数据库时,一个用户的事务处理不能被其他用户的事务所干扰,多个并发事务之间相互隔离 持久性:是指一个事务一旦被提交,他对数据库中的数据改变是永久的 举例说明 1234567891011121314151617181920212223242526create table user2(id int primary key auto_increment,name char(32),balance int);insert into user2(name,balance)values('wsb',1000),('egn',1000),('ysb',1000);#原子操作start transaction;update user2 set balance=900 where name='wsb'; #买支付100元update user2 set balance=1010 where name='egon'; #中介拿走10元update user2 set balance=1090 where name='ysb'; #卖家拿到90元commit;#出现异常，回滚到初始状态start transaction;update user2 set balance=900 where name='wsb'; #买支付100元update user2 set balance=1010 where name='egon'; #中介拿走10元uppdate user2 set balance=1090 where name='ysb'; #卖家拿到90元,出现异常没有拿到rollback; 下面是操作：当p_return_code为1时，表示异常，立马回滚。当为2时，出现警告，立马回滚原始状态。0表示成功 1234567891011121314151617181920212223242526272829303132delimiter //create PROCEDURE b6( OUT p_return_code tinyint)BEGIN DECLARE exit handler for sqlexception BEGIN -- ERROR set p_return_code = 1; rollback; END; DECLARE exit handler for sqlwarning BEGIN -- WARNING set p_return_code = 2; rollback; END; START TRANSACTION; insert into blog(name,sub_time) values('yyy',now()); COMMIT; -- SUCCESS set p_return_code = 0; #0代表执行成功END //delimiter ;set @res=123;call b6(@res);select @res; 索引一.索引的介绍数据库中专门用于帮助用户快速查找数据的一种数据结构。类似于字典中的目录，查找字典内容时可以根据目录查找到数据的存放位置吗，然后直接获取。 二.索引的作用约束和加速查找 三.常见的几种索引 普通索引 唯一索引 主键索引 联合索引 联合主键索引 联合唯一索引 联合普通索引 无索引： 从前往后一条一条查询 有索引：创建索引的本质，就是创建额外的文件（某种格式存储，查询的时候，先去格外的文件找，定好位置，然后再去原始表中直接查询。但是创建索引越多，会对硬盘也是有损耗。 建立索引的目的： a.额外的文件保存特殊的数据结构 b.查询快，但是插入更新删除依然慢 c.创建索引之后，必须命中索引才能有效 四.索引的种类hash索引和BTree索引 hash类型的索引：查询单条快，范围查询慢 btree类型的索引：b+树，层数越多，数据量指数级增长（我们就用它，因为innodb默认支持它） 五.索引的实现原理数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 为表设置索引要付出代价的 一是增加了数据库的存储空间, 二是在插入和修改数据的时候要花费较多的时间(因为索引也要随之变动) 六.索引详细解释普通索引作用:仅有一个加速查找 1234567创建表+普通索引create table userinfo( nid int not null auto_increment primary key, name varchar(32) not null, email varchar(64) not null, index ix_name(name) ); 12普通索引create index 索引的名字 on 表名(列名) 12删除索引drop index 索引的名字 on 表名 12查看索引show index from 表名 唯一索引唯一索引的两个功能:加速查找和唯一约束(可含null) 1234567创建表和唯一索引create table userinfo( id int not null auto_increment primary key, name varchar(32) not null, email varchar(64) not null, unique index ix_name(name) ); 12唯一索引create unique index 索引名 on 表名(列名) 12删除唯一索引drop index 索引名 on 表名; 主键索引主键索引的两个功能:加速查找和唯一约束(可含null) 1234567891011121314151617 创建表和主键索引 create table userinfo( id int not null auto_increment primary key, name varchar(32) not null, email varchar(64) not null, unique index ix_name(name) ) orcreate table userinfo( id int not null auto_increment, name varchar(32) not null, email varchar(64) not null, primary key(nid), unique index ix_name(name) ) 12创建主键索引alter table 表名 add primary key(列名); 123删除主键索引alter table 表名 drop primary key;alter table 表名 modify 列名 int, drop primary key; 组合索引组合索引是将n个列组合成一个索引 12联合普通索引create index 索引名 on 表名(列名1,列名2); 七.索引名词1234覆盖索引:在索引文件中直接获取数据select name from userinfo where name = 'alex50000';索引合并:把多个单例索引合并使用select * from userinfo where name = 'alex13131' and id = 13131; 八.索引注意事项123456789(1)避免使用select *(2)count(1)或count(列) 代替count(*)(3)创建表时尽量使用char代替varchar(4)表的字段顺序固定长度的字段优先(5)组合索引代替多个单列索引（经常使用多个条件查询时）(6)尽量使用短索引 （create index ix_title on tb(title(16));特殊的数据类型 text类型）(7)使用连接（join）来代替子查询(8)连表时注意条件类型需一致(9)索引散列（重复少）不适用于建索引，例如：性别不合适 数据库的引擎mysql所支持的引擎123show engines\G;查看所有支持的引擎show variables like 'storage_engine%'; 查看正在使用的存储引擎create table t1(id int)engine=innodb;# 指定表类型/存储引擎 默认不写就是innodb 1.innoDB存储引擎支持事务,其设计目标主要面向联机事务处理(OLTP)的应用,其特点是行锁的设计,支持外键,并支持类似oracle的非锁定读,即默认读取操作不会产生锁,从mysql5.58版本开始是默认的存储引擎 2.MylSAM存储引擎不支持事务,表锁设计,支持全文索引,主要面向一些OLAP数据库应用,在mysql5.58版本之前是默认的存储引擎,(除 Windows 版本外 )数据库系统 与文件系统一个很大的不同在于对事务的支持,MyISAM 存储引擎是不支持事务的。究其根 本,这也并不难理解。用户在所有的应用中是否都需要事务呢?在数据仓库中,如果没有 ETL 这些操作,只是简单地通过报表查询还需要事务的支持吗?此外,MyISAM 存储引擎的 另一个与众不同的地方是,它的缓冲池只缓存(cache)索引文件,而不缓存数据文件,这与 大多数的数据库都不相同。 3.NDB存储引擎 NDB 存储引擎是一个集群存储引擎,类似于 Oracle 的 RAC 集群,不过与 Oracle RAC 的 share everything 结构不同的是,其结构是 share nothing 的集群架构,因此能提供更高级别的 高可用性。NDB 存储引擎的特点是数据全部放在内存中(从 5.1 版本开始,可以将非索引数 据放在磁盘上),因此主键查找(primary key lookups)的速度极快,并且能够在线添加 NDB 数据存储节点(data node)以便线性地提高数据库性能。由此可见,NDB 存储引擎是高可用、 高性能、高可扩展性的数据库集群系统,其面向的也是 OLTP 的数据库应用类型。 4、Memory 存储引擎正如其名,Memory 存储引擎中的数据都存放在内存中,数据库重 启或发生崩溃,表中的数据都将消失。它非常适合于存储 OLTP 数据库应用中临时数据的临时表,也可以作为 OLAP 数据库应用中数据仓库的维度表。Memory 存储引擎默认使用哈希 索引,而不是通常熟悉的 B+ 树索引。 5.Infobright 存储引擎第三方的存储引擎。其特点是存储是按照列而非行的,因此非常 适合 OLAP 的数据库应用。其官方网站是 http://www.infobright.org/,上面有不少成功的数据 仓库案例可供分析。 6、NTSE 存储引擎网易公司开发的面向其内部使用的存储引擎。目前的版本不支持事务, 但提供压缩、行级缓存等特性,不久的将来会实现面向内存的事务支持 7、BLACKHOLE黑洞存储引擎，可以应用于主备复制中的分发主库。 数据库的锁表级别锁(table-level)表级别的锁定是mysql个存储引擎中最大颗粒度的锁定机制,该锁定最大的特点就是实现逻辑非常简单,带来的系统负面影响最小,所以获取锁和释放锁都非常快,由于表级锁一次会将整个表都锁住,所以可以很好的避免死锁的问题 使用表级锁的主要是:myiSAM,MEMORY,CSV等一些非事务型存储引擎 行级锁(row-level)行级锁最大的特点就是锁定对象的颗粒度很小,也是目前各大数据库管理软件所实现的锁定颗粒度最小的,由于颗粒度很小,所以发生多锁定字段争用的概率也是最小的,能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能 虽然在并发处理上有很大的优势,但是行级索引也因此带来很多的弊端,由于锁定资源的颗粒度很小,所以每次获取和释放锁需要做的事情也多了,因此带来的消耗也就大了,行级锁很容易带来死锁 使用行级锁的主要是innoDB存储引擎 页级锁定(page-level)页级锁定是mysql中比较独特的一种锁定级别,在其他的数据库管理中不是太常见,页级锁定的特点:锁定颗粒度介于行级锁和表级锁之间的,所以获取锁定所需要的开销以及所能够提供的并发处理能力也是介于上面两者之间的, 使用页级锁定的主要是berkeleyDB存储引擎 总结表级锁:开销小.加锁快,不会出现死锁;锁定粒度大,发生锁冲突的概率最高,并发度最低 行级锁:开销大,加锁慢,会出现死锁,锁定粒度最小,发生锁冲突概率最低,并发程度最高 页面锁:开锁和加锁时间介于表锁和行锁之间,会出现死锁;锁定粒度介于表锁和行锁之间,并发一般 应用三个锁之间各有各的特点,如果从锁的角度来说,表级锁更适合查询为主,只有少量按索引条件更新数据的应用 ,如web应用;航迹锁更适用于有大量按索引条件,并发更新少量不同数据,同时又有并发查询的应用,如一些在线事务处理(OLTP)系统 MYSQL表级锁有两种模式 表共享读锁(Table Read Lock) 对mylSAM表进行读取操作时不会阻塞其他用户对同一表的写操作 表独占写锁(Table write Lock) 对MylSAM表的写操作,则会阻塞对其他用户对同一表的读写操作 innoDB和MyiSAM锁最大的不同 InnoDB支持事务,Myisam不支持 innoDB可以使用行级锁和表锁,MyiSAM只支持表锁 视图1.视图的定义视图是虚拟表或逻辑表，它被定义为具有连接的SQL SELECT查询语句。因为数据库视图与数据库表类似，它由行和列组成，因此可以根据数据库表查询数据。其内容由查询定义。 但是，视图并不在数据库中以存储的数据值集形式存在，行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。简单的来说视图是由其定义结果组成的表； 2.视图的优点1.数据库视图允许简化复杂查询，通过数据库视图，您只需使用简单的SQL语句，而不是使用具有多个连接的复杂的SQL语句。2.安全性。一般是这样做的:创建一个视图，定义好该视图所操作的数据。之后将用户权限与视图绑定。这样的方式是使用到了一个特性：grant语句可以针对视图进行授予权限。 3.视图的缺点1、性能：从数据库视图查询数据可能会很慢，特别是如果视图是基于其他视图创建的。 2、表依赖关系：将根据数据库的基础表创建一个视图。每当更改与其相关联的表的结构时，都必须更改视图。 4.创建视图语法: create view 视图名称 as sql语句 12create view teacher_view as select tid from teacher where tname='李平老师';select cname from course where teacher_id = (select tid from teacher_view); 5.使用视图12345往真实表中插入一条数据，查看一下视图，发现视图表也会跟着更新insert into course(cname,teacher_id) values('张三丰',2);更新一下数据，发现视图的数据也会跟着更新update course set cname='王五';不能修改视图的数据 6.修改视图12语法：ALTER VIEW 视图名称 AS SQL语句alter view teacher_view as select * from course where cid&gt;3; 7.删除视图12语法：DROP VIEW 视图名称DROP VIEW teacher_view 触发器触发器:触发器是一个特殊的存储过程，它是MySQL在insert、update、delete的时候自动执行的代码块。 1.创建触发器1234567891011121314151617181920212223242526272829303132333435# 插入前CREATE TRIGGER tri_before_insert_tb1 BEFORE INSERT ON tb1 FOR EACH ROWBEGIN ...END# 插入后CREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROWBEGIN ...END# 删除前CREATE TRIGGER tri_before_delete_tb1 BEFORE DELETE ON tb1 FOR EACH ROWBEGIN ...END# 删除后CREATE TRIGGER tri_after_delete_tb1 AFTER DELETE ON tb1 FOR EACH ROWBEGIN ...END# 更新前CREATE TRIGGER tri_before_update_tb1 BEFORE UPDATE ON tb1 FOR EACH ROWBEGIN ...END# 更新后CREATE TRIGGER tri_after_update_tb1 AFTER UPDATE ON tb1 FOR EACH ROWBEGIN ...END 1234567891011121314151617181920212223242526272829# 创建用户表create table user( id int primary key auto_increment, name varchar(20) not null, reg_time datetime, # 注册用户的时间 affirm enum('yes','no') # no表示该用户执行失败);#创建日志表create table userLog( id int primary key auto_increment, u_name varchar(20) not null, u_reg_time datetime # 注册用户的时间);# 创建触发器 delimiter 默认情况下，delimiter是分号 触发器名称应遵循命名约定[trigger time]_[table name]_[trigger event]delimiter //create trigger after_user_insert after insert on user for each rowbegin if new.affirm = 'yes' then insert into userLog(u_name,u_reg_time) values(new.name,new.reg_time); end if;end //delimiter ;#往用户表中插入记录，触发触发器，根据if的条件决定是否插入数据insert into user(name,reg_time,affirm) values ('张三',now(),'yes'),('李四',now(),'yes'),('王五',now(),'no'); 注意:请注意，在为INSERT定义的触发器中，可以仅使用NEW关键字。不能使用OLD关键字。但是，在为DELETE定义的触发器中，没有新行，因此您只能使用OLD关键字。在UPDATE触发器中，OLD是指更新前的行，而NEW是更新后的行 2.使用触发器触发器无法由用户直接调用,而只能由于对表的[增删改查]操作被动引起的 3.删除触发器1drop trigger trigger_userLog;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基础]]></title>
    <url>%2F2019%2F01%2F14%2Fmysql%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[mysql数据库基本命令数据库的增删改查12345678910111213-- 增create database 数据库名称;-- 删drop database 库名;-- 改alter database 库名 更改的内容;-- 查show create database 库名;查看当前创建的数据库show databases; 查看所有的数据库select database();查看所在的数据库 表的增删改查1234567891011121314-- 增create table 表名(字段名 类型 约束);-- 删drop table 表名;-- 改alter table 表名 modify 字段名 类型;alter table 表名 add 字段名;-- 查show create table 表名;查看表的详细信息show tables;查看这个数据库先所有的表desc 表名;查看这个表里面所有的字段 数据的增删改查123456789101112131415-- 增insert into 表名(字段名) values (内容);-- 删delete from 表名; 清空数据,但是里面的id自增不会去除truncate 表名; 删除所有的内容-- 改update 表名 set name="xxx" where 条件update 表名 set 要修改的内容-- 查select 字段名 from 表名;select 字段1,字段2 from 表名;select * from 表名; 查看所有的内容 mysql的数据类型数据类型:定义列中可以存储什么数据以及该数据实际怎样存储的基本规则，其用于以下几个目的 允许限制可存储在列中的数据 允许在内部更有效的存储数据 允许变换排序顺序（作为数值数据类型，数值才能正确排序） 一.字符串数据类型该类型为最常用的数据类型，用来存储串（比如名字、地址等）；有两种串类型，分别是定长串和变长串 定长串：接受长度固定的字符串，其长度实在创建表时指定的；定长列不允许多余指定的字符数目，它们分配的存储空间与指定的一样多（比如char） 变长串：存储可变长度的文本，有些变长数据类型具有最大定长，有些是完全变长的，不论哪种，指定的数据得到保存即可（灵活） 数据类型 大小 用途 char 0-255字节 定长字符串 varchar 0-65535字节 变长字符串 tinyblog 0-255字节 不超过255个字符的二进制字符串 tinytext 0-255字节 短文本字符串 blob 0-65535字节 二进制形式的长文本数据 text 0-65535字节 长文本数据 mediumblob 0-16777215字节 二进制形式的中等长度文本数据 mediumtext 0-16777215字节 中等长度文本数据 二.数值类型 类型 大小 范围(有符号) 无符号 用途 tinyint 1字节 (-128,127) (0,255) 小整数值 smallint 2字节 (-32768,32767) (0,35535) 大整数值 mediumint 3字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 int或integer 4字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 bigint 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 float 4字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 double 8字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 decimal 对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 三.日期和时间类型表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。 类型 大小(字节) 范围 格式 用途 date 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 time 3 -838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 year 1 1901/2155 YYYY 年份值 datetime 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 timestamp 4 1970-01-01 00:00:00/2038结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 四.枚举和集合 enum 单选只能在给定的范围内选一个值,如sex男和male女 set 多选 在给定的范围内可以选择一个或一个以上的值(爱好1,爱好2) 完整性约束 类型 说明 not null 不能为空 default 默认值 unique 设置唯一 primary key 主键 auto_increment 自增 foreign key 外键 unsigned 无符号 zerofill 使用0填充 on delete cascade 同步删除 on update cascade 同步更新 表查询单表查询 from: 找表 where :指定约束条件 比较运算符:&gt;,&lt;,&gt;=,&lt;=,!= between 80 and 100 :值在80到100之间 in(80,90,100):值是80,90或100 like’xiaomage‘:模糊查找也可以是%,或_:模糊查找 逻辑运算符:and or not group by:分组 having:过滤 执行优先级:where&gt;group by &gt;having 1.where 发生在分组 group by之前,因而where 中可以有任意字段,但绝对不能使用聚合函数 2.having 发生在分组 group by之后,因而having中可以使用分组字段,无法直接取到其他字段,可以使用其他函数 select :挑选 distinct:去重 order by:排序 asc:正序 小–&gt;大 DESC:倒序 大—-&gt;小 limit:限制结果的显示条数 第一个是:起始位置 第二个是:显示的条数 多表查询 select 字段 from 表1 inner | left |right join 表2 on 表1.字段 = 表2.字段 inner 是只连接匹配的行 right:外键之右连接:优先显示右半部分 left:外键之左连接:优先显示左半部分 union:连接left和right:可以显示全部信息 符合条件的连接查询 on:后面加两个表的比较条件 子查询 子查询是将一个查询语句嵌套在另一个查询语句中 内层查询语句的查询结果,可以为外层查询语句提供条件 子查询中可以包含:in ,not,any,all,exists和not exists EXISTS:判断的是真和假,有内容为真,没有就是假 聚合函数 函数名 说明 max() 求最大值 min() 求最小值 avg() 求平均值 sum() 求和 count() 求总个数 group_concat(name): 查找这个组里所有的名字 pymsql的使用(python)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import pymysql1.连接 host:数据库地址 port:端口 user:用户名 password:密码 db:数据库 charset:指定类型conn = pymysql.connect(host='127.0.0.1', port=3306, user='root', password='', db='db8', charset='utf8') 2.创建游标cursor = conn.cursor()# 防止注入sql = "select * from userinfo where username='%s' and pwd='%s'" cursor.execute(sql,[user,pwd])# 增# 一条sql = "insert into userinfo(username,pwd,) values(xx,oo)" cursor.execute(sql)# 多条cursor.executemany(sql,[(),(),()])# 删sql = "delete from userinfo where id = 2"cursor.execute(sql)# 改sql = "update userinfo set userinfo=%s where id = 2"cursor.execute(sql,username)# 查fetchone():获取下一行数据，第一次为首行；fetchall():获取所有行数据源fetchmany(4):获取4行数据sql = 'select * from userinfo'cursor.execute(sql)# 查询第一行的数据row = cursor.fetchone() # 获取查询的指定条数的信息ret = cursor.fetchmany(3)# 获取查询的所有信息ret = cursor.fetchall()# ------------------事务--------------sql = "insert into userinfo(name,password) values(%s,%s)"try: # 执行SQL语句 res = cursor.execute(sql,["rain222","1234"]) # 提交事务 conn.commit() # 提交之后，获取刚插入的数据的ID last_id = cursor.lastrowidexcept Exception as e: # 有异常，回滚事务 conn.rollback()# ----------------------------------------# 移动指针cursor.scroll(1,mode='relative') # 相对当前位置移动cursor.scroll(2,mode='absolute') # 相对绝对位置移动第一个值为移动的行数，整数为向下移动，负数为向上移动，mode指定了是相对当前位置移动，还是相对于首行移动# 关闭连接，游标和连接都要关闭cursor.close()conn.close() 数据库的备份和还原备份1234567891011-- 备份一个数据库基本语法mysqldump -u username -p dbname table1 table2 ...-&gt; BackupName.sql dbname参数表示数据库的名称； table1和table2参数表示需要备份的表的名称，为空则整个数据库备份； BackupName.sql参数表设计备份文件的名称，文件名前面可以加上一个绝对路径。通常将数据库被分成一个后缀名为sql的文件；-- 备份多个数据库mysqldump -u username -p --databases dbname2 dbname2 &gt; Backup.sql 加上了--databases选项，然后后面跟多个数据库-- 备份所有数据库mysqldump -u -root -p -all-databases &gt; D:\all.sql 还原1mysql -u root -p &lt; C:\backup.sql 注意：这种方法不适用于InnoDB存储引擎的表，而对于MyISAM存储引擎的表很方便。同时，还原时MySQL的版本最好相同。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git学习笔记]]></title>
    <url>%2F2019%2F01%2F14%2Fgit%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[安装git12git config --global user.name "Your Name"git config --global user.email "email@example.com" 管理工作目录1234git init 初始化git status 查看工作树状态git log--oneline 查看提交记录git reflog 查看之前所有的操作记录 三种状态/区域的切换12345678工作区 暂存区 本地仓库git add ./&lt;filename&gt; 工作区到暂存区git commit -m "理由" 暂存区到本地仓库git checkout ./&lt;filename&gt; 丢弃工作区的内容git reset ./&lt;filename&gt; 从暂存区回退到工作区git reset --hard &lt;commit_id&gt; 版本的回退,并删除git reset --soft &lt;commit_id&gt; 把内容存到暂存区git reset &lt;commit_id&gt; 把内容回退到工作区 分支管理12345git branch &lt;name&gt; 创建分支git branch :查看分支git branch -d &lt;name&gt; 删除分支git checkout &lt;name&gt; 切换分支git merge &lt;name&gt; 把name分支合并到当前分支 标签管理123git tag &lt;name&gt; &lt;commit_id&gt; 给指定的版本加标签git tag 查看所有标签git tag -d &lt;name&gt; 删除标签 远程仓库建立连接123--ssh1.本地生成公钥私钥,在主用户的根目录下2.把公钥放入github中 和远程仓库建立连接1git remote add '远程仓库的别名' 远程仓库的地址 查看所有的仓库1git remote 向远程仓库提交代码12git push -u 远程仓库别名 分支名注意 -u 第一次提交代码的时候本地分支跟远程仓库的分支建立起连接 从远程仓库拉代码1git pull 远程仓库的别名 分支名 克隆项目1git clone 地址]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go基础部分]]></title>
    <url>%2F2019%2F01%2F14%2Fgo%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[基础语法变量定义12345678910111213141516变量需要先声明,再赋值// 声明:var a int // 声明int类型的变量var b [10]int // 声明int类型的数组var c []int // 声明int类型的切片var d *int // 声明int类型的指针// 赋值a = 10b[0] = 10// 同时声明与赋值var a = 10a := 10a,b,c,d := 1,2,true,"xxx" 常量定义123456789101112131415// const是用来定义常量的const filename = "abc.txt"const a,b = 3,4 const ( python = 1 go = 2 java = 3)const( python = iota //自增,初始值为0 go java) 条件语句和循环if条件语句123456789101112if a == 100&#123; return "满分"&#125;else if a &gt;=60&#123; return "及格"&#125;else&#123; return "不及格"&#125;if a,b := 1,2; a + b == 3&#123; fmt.Println(a,b)&#125;fmt.Println(a,b) // 此处会报错,a和b是在if里定义的,作用域仅限于if 中使用 switch条件语句12345678910111213141516// go中的switch会自动break,除非使用fallthroughk:= 1switch k &#123; case 1: fmt.Println(1) case 2: fmt.Println(2) case 3: fmt.Println(3) case 4: fmt.Println(4) case 5: fmt.Println(5) default: fmt.Println(6)&#125; for循环12345678910111213141516171819// 赋值语句；判断语句；递增语句for i:=100; i&gt;0; i--&#123; fmt.Println(i)&#125;// 无赋值func test(n int)&#123; for ; n&gt;0 ; n/=2 &#123; fmt.Println(n); &#125;&#125;// 仅赋值scanner := bufio.NewScanner(file)for scanner.Scan()&#123; fmt.Println(scanner.Text);&#125;// 死循环for&#123; fmt.Println(1);&#125; 函数123456789101112131415161718192021222324// 格式func eval(a,b int, s string) int&#123; ... &#125;// 当有返回多个值时func test1(a,b int) (int, int)&#123; return a+b, a*b&#125;// 为多个返回值起名字（仅用于简单函数）func test2(a,b int) (q, r int)&#123; q = a+b r = a*b return // 自动对号入座返回相应变量&#125;q, r := test2(1,2)// 输出错误func test(a,b int)(int, error) &#123; if a+b&gt;100&#123; return a+b, fmt.Errorf("%s","error!") &#125;else&#123; return a+b, nil &#125;&#125; 指针1234567891011// go语言的参数传递是值传递func main()&#123; a,b := 1,2 swap_text(&amp;a,&amp;b)&#125;func swap_text(a,b *int)&#123; fmt.Println(a,*b) // 0xc420014050 2&#125;// 理解： a,b *int 存的是 int 类型值的地址，当对指针类型的变量 *a 时，就是取出地址对应的值 内建容器数组定义数组1234var arr [3]int // 会初始化为 [0,0,0]arr := [3]int&#123;1,2,3&#125; // [1,2,3] 只能存放三个arr := [...]&#123;1,2,3,4,5&#125; // [1,2,3,4,5] 不用在意多少arr := [2][4]int // 2行4列 遍历数组1234arr := [3]int&#123;1, 2, 3&#125;for k, v := range arr &#123; fmt.Println(k, v)&#125; 函数传递(按值传递)1234567891011// 注意,[5]int 与 [10]int是不同类型的// go语言一般不直接使用数组,而是使用切片func printArr(arr [5]int) &#123; for k,v:=range (arr)&#123; fmt.Println(k,v) &#125;&#125;func main() &#123; arr :=[5] int &#123;6,7,8,9,10&#125; printArr(arr)&#125; 切片概念123456// 顾首不顾尾arr := [...]&#123;0,1,2,3,4,5,6,7&#125;arr1 := arr[1:2] // 1arr2 := arr[:5] // 0,1,2,3,4arr3 := arr[2:] // 2,3,4,5,6,7arr4 := arr[:] // 0,1,2,3,4,5,6,7 视图1234567891011// 切片是数组的 "视图" , 即引用func updateArr(arr []int) &#123; // []中不写具体大小，表示是切片，引用传递 arr[0] = 100&#125;func main() &#123; arr :=[5] int &#123;0,1,2,3,4&#125; arr1 := arr[1:3] fmt.Println(arr,arr1) // [0 1 2 3 4] [1 2] updateArr(arr1) fmt.Println(arr,arr1) // [0 100 2 3 4] [100 2]&#125; 切片的扩展(cap) 123456789101112131415161718// 切片的切片依然是对一个数组的引用func updateArr(arr []int) &#123; arr[0] = 100&#125;func main() &#123; arr :=[5] int &#123;0,1,2,3,4&#125; arr1 := arr[1:3] arr2 := arr1[0:3] fmt.Println(arr,arr1,arr2) // [0 1 2 3 4] [1 2] [1 2 3] updateArr(arr1) fmt.Println(arr,arr1,arr2) // [0 100 2 3 4] [100 2] [100 2 3]&#125;// 查看扩展arr :=[5] int &#123;0,1,2,3,4&#125;arr1 := arr[1:3]arr2 := arr1[0:3]fmt.Println(arr1,len(arr1),cap(arr1)) // [1 2] 2 4fmt.Println(arr2,len(arr2),cap(arr2)) // [1 2 3] 3 4 直接创建切片123a := []int&#123;1,2,3&#125;var a []int //会初始化为nila := make([]int,16,32) // make(切片类型,切片长度,切片cap长度) 添加元素123456789101112131415161718192021222324252627282930// 若添加元素个数不超过cap值,则在原数组修改arr :=[5] int &#123;0,1,2,3,4&#125;arr1 := arr[1:3]arr2 := append(arr1, 10, 11)fmt.Println(arr1,arr2,arr) // [1 2] [1 2 10 11] [0 1 2 10 11]//若添加元素个数超过cap值,则开辟新的数组,拷贝并添加arr :=[5] int &#123;0,1,2,3,4&#125;arr1 := arr[1:3]arr2 := append(arr1, 10, 11, 12)fmt.Println(arr1,arr2,arr) // [1 2] [1 2 10 11 12] [0 1 2 3 4]func main() &#123; var s []int for i:=0; i&lt;10; i++ &#123; s = append(s,i) fmt.Println(s, cap(s)) &#125;&#125;// 结果：（当cap超出，就会重新分配cap值更大的新数组）[0] 1[0 1] 2[0 1 2] 4[0 1 2 3] 4[0 1 2 3 4] 8[0 1 2 3 4 5] 8[0 1 2 3 4 5 6] 8[0 1 2 3 4 5 6 7] 8[0 1 2 3 4 5 6 7 8] 16[0 1 2 3 4 5 6 7 8 9] 16 copy(拷贝)1234s1 := []int&#123;0,1,2,3&#125;s2 := make([]int,6)copy(s2,s1) // 把s1中的内容拷贝到s2中fmt.Println(s1,s2) // [0 1 2 3] [0 1 2 3 0 0] map定义123456789m := map[string]int&#123;&#125; // nilvar m map[string]string // nilm := make(map[string]string) // empty mapm2 := map[string]string&#123; "name":"xxx", "age":"111"&#125;fmt.Println(m2) // map[name:xxx age:111] 遍历12345678// map是无序的hash map,所以遍历时每一次输出的顺序都不一样m := map[string]string&#123; "name":"xxx", "age":"111"&#125;for k,v := range m&#123; fmt.Println(k,v)&#125; 取值123456789101112131415161718192021m := map[string]string&#123; "name":"xxx", "age":"111"&#125;name := m["name"] mt.Println(name) // "xxx"// 获取一个不存在的值sex := m["sex"]mt.Println(sex) // 返回一个空值// 判断key是否存在value,ok := m["aaa"]mt.Println(value,ok) // 返回一个空和false// 标准用法if v,ok := m["age"]; ok&#123; fmt.Println(v)&#125;else&#123; fmt.Println("key not exist")&#125; 删除(delete)1delete(m,"age") // 删除m中的age 面对对象1// go语言的面对对象仅支持封装,不支持继承和多态 结构体定义123456789101112131415161718// 定义一个结构体type treeNode struct&#123; value int left,right *treeNode&#125;func main()&#123; root := treeNode&#123;1,nil,nil&#125; node1 := treeNode&#123;value:3&#125; root.left = &amp;node1 root.left.right = new(treeNode) // 内建函数初始化node new(treeNode) = &amp;&#123;0 &lt;nil&gt; &lt;nil&gt;&#125; nodes := []treeNode&#123; &#123;1,nil,nil&#125;, &#123;2,&amp;root,&amp;node1&#125;, &#125; fmt.Println(nodes[1].left.left.value) // 3&#125; 自定义工厂函数123456789// 由于没有构造函数,所以可以用工厂函数替代func createNode(value int) *treeNode&#123; return &amp;treeNode&#123;value:value&#125;&#125;func main()&#123; node := createNode(10) fmt.Println(node) // &amp;&#123;10,&lt;nil&gt;,&lt;nil&gt;&#125;&#125; 结构体方法123456789101112131415161718192021// 结构体方法并不是写在结构体中,而是像函数一样写在外面,他实际上就是定义了[接收对象]的函数// 由于本质依然是函数,所以按值传递,若要改变对象,需要用指针传递type treeNode struct&#123; value int left,right *treeNode&#125;// func(接收对象) 方法名(参数) 返回值&#123;&#125;func (node treeNode) get() int&#123; return node.value&#125;func (node *treeNode) set(value int)&#123; node.value = value&#125;func main()&#123; root := treeNode&#123;2,nil,nil&#125; res := root.get() root.set(10)&#125; 封装123// 名字一般用CamelCase(驼峰体)// 首字母大写是public(公有方法,可以调用)方法// 首字母小写是private(私有方法)方法 包123// 每个目录只有一个包(package)// main包 包含程序入口// 为某结构体定义方法必须放在同一包内,但可以放不同文件 继承123go语言没有继承,如何扩展系统类型或者自定义类型呢? 1.定义别名 2.使用组合 获取第三方库12// go get xxx 从第官方下载第三方库,需要翻墙// gopm 可以获取国内镜像 (需要在github下载gopm) 接口定义123type xxx interface&#123; FuncName() string // 定义接口方法与返回类型&#125; 实现12345678910111213141516171819202122232425262728293031323334// 结构体不需要显示"实现" 接口,只要定义好方法即可// interface/interface.gopackage filetype File interface &#123; Read() string Write(str string)&#125;// interface/implament.go// File1 结构体实现了接口规定的方法package filetype File1 struct &#123; Content string&#125;func (file File1) Read() string&#123; return file.Content&#125;func (file *File1) Write(str string) &#123; file.Content = str&#125;// interface/entry/main.gopackage mainimport ( "../../interface" "fmt")func get(f file.File) string &#123; // 只有实现了 File 接口的结构体实例才能调用此方法 res := f.Read() return res&#125;func main() &#123; f := file.File1&#123;&#125; f.Write("www") fmt.Println(get(f))&#125; 类型123456// 查看类型 i.(type)var i AnimalInterface // 定义变量 i 是动物接口类型i = Cat&#123;"cat"&#125; // 假设 Cat 结构体实现了 AnimalInterface 接口i.(type) // Cati = Dog&#123;"dog"&#125; // 假设 Dog 结构体实现了 AnimalInterface 接口i.(type) // Dog 约束接口类型: i.(xxx)12345678var i AnimalInterface // 定义变量 i 是动物接口类型i = Cat&#123;"cat"&#125; // 假设 Cat 结构体实现了 AnimalInterface 接口cat := i.(Cat) // 如果 i 是Cat类型的，则拷贝赋值给 cat变量，否则报错）if dog, ok := i.(Dog); ok&#123; // ok&#125;else&#123; // i isn't dog&#125; 泛型:interface{}123456789101112131415161718192021type Queue []int // 定义了一个 int 类型的切片func (q *Queue) Push(v int)&#123; *q = append(*q, v)&#125;func (q *Queue) Pop() int&#123; head := (*q)[0] *q = (*q)[1:] return head&#125;// 将上面的切片改成可以接受任意类型：type Queue []interface&#123;&#125; // 定义了一个 int 类型的切片func (q *Queue) Push(v interface&#123;&#125;)&#123; *q = append(*q, v)&#125;func (q *Queue) Pop() interface&#123;&#125;&#123; head := (*q)[0] *q = (*q)[1:] return head&#125;// 强制类型转换：head.(int) 组合1234567891011121314type Cat interface&#123; cat()&#125;type Dog interface&#123; dog()&#125;type Animal interface&#123; // 要实例既实现 Cat 又实现 Dog Cat Dog&#125;func get(i Animal)&#123; i.cat() i.dog()&#125; 常用系统接口123456789101112// 1. 类似 toString() 的信息打印接口type Stringer interface&#123; String() string&#125;// 2. Readertype Reader interface&#123; Read(p []byte) (n int, err error)&#125;// 3. Writertype Writer interface&#123; Write(p []byte) (n int, err error)&#125; 函数式编程闭包12345678910111213func add() func(int) int &#123; sum := 0 // 此处的 sum 为自由变量 return func(v int) int &#123; sum += v // 指向外层sum return sum &#125;&#125;func main()&#123; add := add() for i:=0; i&lt;10; i++ &#123; fmt.Printf(add(i)) // 从 0 到 10 的累加 &#125;&#125; 生成器123456789101112131415// 一个斐波那契数列的生成器func fib() func() int&#123; a, b := 0, 1 return func() int&#123; a, b = b, a+b return a &#125;&#125;func main()&#123; f = fib() f() // 1 f() // 1 f() // 2 f() // 3&#125; 函数接口12345678910111213141516171819202122232425262728293031323334package mainimport ( "io" "bufio" "fmt" "strings")type funcType func() intfunc fib() funcType&#123; a, b := 0, 1 return func() int&#123; a, b = b, a+b return a &#125;&#125;func (f funcType) Read(p []byte) (n int, err error) &#123; next := f() if next &gt; 1000 &#123; return 0, io.EOF &#125; s := fmt.Sprintf("%d ", next) return strings.NewReader(s).Read(p)&#125;func scan(read io.Reader) &#123; scanner := bufio.NewScanner(read) for scanner.Scan() &#123; text := scanner.Text() fmt.Printf(text) &#125;&#125;func main() &#123; f := fib() scan(f)&#125; 错误处理与资源管理defer123456789101112131415func writeFile(filename string) &#123; file, err := os.Create(filename) if err!=nil &#123; panic("创建文件失败！") // 打印错误信息 &#125; defer file.Close() // 函数执行完毕前。关闭文件句柄 writer := bufio.NewWriter(file) defer writer.Flush() // 函数执行完毕前，将缓冲区中的内容刷新到文件中去 for i:=0; i&lt;100; i++ &#123; fmt.Fprintln(writer,i) // 写入缓冲区 &#125;&#125;func main() &#123; writeFile("1.txt")&#125; panic与recover123456789panic: 1.停止当前函数执行 2.停止之前,执行每层defer 3.如果没有recover 程序直接退出recover: 1.近在defer中调用 2.可以获取 panic 的值 3.如果无法处理,可重新 panic 12345678910111213141516171819202122232425262728293031323334353637383940// 例一：捕获 panicfunc dopanic()&#123; defer func() &#123; err := recover() fmt.Println(err) // error!! &#125;() panic("error!!")&#125;func main() &#123; dopanic()&#125;// 例二：捕获其他异常func dopanic()&#123; defer func() &#123; err := recover() fmt.Println(err) // runtime error: integer divide by zero &#125;() a := 0 b := 1/a fmt.Println(b)&#125;func main() &#123; dopanic()&#125;// 例三：无异常处理func dopanic()&#123; defer func() &#123; err := recover() if err, ok := err.(error); ok&#123; fmt.Println(err) &#125;else&#123; fmt.Println("no error!") &#125; &#125;() a := 0 fmt.Println(a)&#125;func main() &#123; dopanic()&#125; goroutine并发goroutine1234567891011121314151617181920212223242526272829// go func()&#123;&#125;()// 用go关键字开启协程,协程是非抢占式多任务处理,有协程主动交出控制权// 第一种func main()&#123; for i := 0; i &lt; 1000; i++&#123; go func(i int)&#123; for &#123; fmt.Println("xxxxx") &#125; &#125;(i) &#125; time.Sleep(time.Millsecond)&#125;// 第二种func main()&#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; for &#123; a[i]++ runtime.Gosched() &#125; &#125;(i) &#125; time.Sleep(time.Microsecond) fmt.Println(a)&#125; go语言调度器12345678// go func()&#123;&#125;() // 用 go 关键字开启协程，协程是非抢占式多任务处理，由协程主动交出控制权goroutine可能交出控制权的点： - I/O操作，select - channel - 等待锁 - 函数调用时（有时，不一定） - runtime.Gosched() channel channel其实就是传统语言的阻塞消息队列，可以用来做不同goroutine之间的消息传递 定义12 更进一步：channel工厂12 channel 方向（只读与只写）12 缓冲区 向管道中写入就必须定义相应的输出，否则会报错 有缓冲区与无缓冲区的区别是 一个是同步的 一个是非同步的，即阻塞型队列和非阻塞队列 详解：https://blog.csdn.net/samete/article/details/52751227 12 关闭管道12 用channel等待任务结束上面的例子使用 time.Sleep(time.Microsecond)来等待任务结束，不精确且耗时 12 用 sync.WaitGroup 等待任务结束1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( "fmt" "sync")type worker struct &#123; in chan int wg *sync.WaitGroup // *&#125;func createWorker(wg *sync.WaitGroup) worker&#123; worker := worker&#123; in:make(chan int), wg:wg, &#125; doWorker(worker); return worker&#125;func doWorker(w worker) &#123; go func(w worker) &#123; for &#123; fmt.Printf("%c \n", &lt;-w.in) w.wg.Done() // 发送任务结束的信号 &#125; &#125;(w)&#125;func main() &#123; var wg sync.WaitGroup // 定义WaitGroup var arr [10] worker for i:=0; i&lt;10; i++ &#123; arr[i] = createWorker(&amp;wg) //按址传递，用一个引用来开始和结束 &#125; for i:=0; i&lt;10; i++ &#123; wg.Add(1) // 开始一个任务前，计时器加一（一定要在开始前加） arr[i].in &lt;- 'a'+i &#125; for i:=0; i&lt;10; i++ &#123; wg.Add(1) arr[i].in &lt;- 'A'+i &#125; wg.Wait() // 阻塞等待所有任务 done&#125; select 有多个 case 语句，只要有一个 case 处于非阻塞可执行状态，就执行，否则一直阻塞 如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行 用法12 12 定时器 time.After() 设置一个定时器，返回一个 channel，到一段时间后，向channel发送一条当前时间 time.Tick() 返回一个 channel，每过一段时间向channel发送一条当前时间 123456789101112131415161718func main() &#123; c1,c2 := create(1),create(2) tm := time.After(2*time.Second) // 定时器，2秒后触发 tm2 := time.Tick(1*time.Second) // 每1秒触发一次 for &#123; select &#123; case n1 := &lt;-c1: fmt.Printf("%c \n",n1) case n2 := &lt;-c2: fmt.Printf("%c \n",n2) case t := &lt;- tm2: fmt.Println("------- ",t," -----------") case &lt;- tm: fmt.Println("bye") return &#125; &#125;&#125;]]></content>
      <categories>
        <category>go语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ的基本使用]]></title>
    <url>%2F2019%2F01%2F14%2FRabbitMQ%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[官网:RabbitMQ RabbitMQ是一个在AMQP基础上完整的，可复用的企业消息系统。他遵循Mozilla Public License开源协议 MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消 息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。 RabbitMQ 安装1234567891011# 安装配置epel源rpm -ivh http://dl.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm# 安装erlangyum -y install erlang# 安装RabbitMQyum -y install rabbitmq-server# 开启和关闭RabbitMQservice rabbitmq-server start/stop 安装API 12345# python3安装pip install pika# python2安装easy_install pik 生产者消费者生产者123456789101112131415161718192021import pika# 无密码# connection = pika.BlockingConnection(pika.ConnectionParameters('IP地址'))# 有密码credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 声明一个队列(创建一个队列) 并支持持久化channel.queue_declare(queue='队列名称',durable=True)channel.basic_publish(exchange='', routing_key='队列名称', # 消息队列名称 body='发送的内容', properties=pika.BasicProperties( delivery_mode = 2, # 对信息进行持久化 )) # 关闭connection.close() 消费者12345678910111213141516171819202122import pika# 连接rabbitMQcredentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 声明一个队列(创建一个队列)channel.queue_declare(queue='队列名称')# 设置闲置时消费,那个消费者消费完了就接收任务channel.basic_qos(prefetch_count=1)# 设置回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body) ch.basic_ack(delivery_tag=method.delivery_tag) # 给服务端发送我接收到了 # 监听队列 no_ack=false 表示给服务端发送我接收到了的消息channel.basic_consume(callback,queue='队列名称',no_ack=False)# 开始监听channel.start_consuming() 发布者和订阅者全部订阅用户发布者 123456789101112131415import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 设置 中间商 exchange_type : fanout(全部) channel.exchange_declare(exchange='中间商名称',exchange_type='fanout')# 向队列添加内容channel.basic_publish(exchange='中间商名称', routing_key='', body='内容')connection.close() 订阅者 123456789101112131415161718192021222324252627import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建中间商(有的话就不会创建)channel.exchange_declare(exchange='中间商名称',exchange_type='fanout')# 随机生成一个队列result = channel.queue_declare(exclusive=True)queue_name = result.method.queu# 让exchange和queque进行绑定.channel.queue_bind(exchange='中间商名称',queue=queue_name)# 设置回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body)# 对队列进行监听channel.basic_consume(callback,queue=queue_name,no_ack=True)# 开始监听channel.start_consuming() 关键字发布发布者 12345678910111213141516import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建中间商 exchange_type direct:代表关键字队列channel.exchange_declare(exchange='中间商名称',exchange_type='direct')channel.basic_publish(exchange='中间商名称', routing_key='关键字', body='内容')# 关闭connection.close() 订阅者 123456789101112131415161718192021222324252627import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建中间商 exchange_type direct:代表关键字队列channel.exchange_declare(exchange='名称',exchange_type='direct')# 随机生成一个队列result = channel.queue_declare(exclusive=True)queue_name = result.method.queue# 让exchange和queque进行绑定. routing_key:指定关键字,可以绑定多次channel.queue_bind(exchange='名称',queue=queue_name,routing_key='关键字1')channel.queue_bind(exchange='名称',queue=queue_name,routing_key='关键字1')# 设置回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body)# 对队列进行监听channel.basic_consume(callback,queue=queue_name,no_ack=True)# 开始监听channel.start_consuming() 模糊匹配发布者 1234567891011121314151617import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建一个中间商 topic:代表模糊匹配channel.exchange_declare(exchange='名称',exchange_type='topic')# 发送数据channel.basic_publish(exchange='m3', routing_key='xxx.xxx.py', body='内容')# 关闭connection.close() 订阅者 1234567891011121314151617181920212223242526import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建一个中间商 topic:代表模糊匹配channel.exchange_declare(exchange='名称',exchange_type='topic')# 随机生成一个队列result = channel.queue_declare(exclusive=True)queue_name = result.method.queue# 让exchange和queque进行绑定. # :代表全部 *代表一个单词channel.queue_bind(exchange='名称',queue=queue_name,routing_key='xxx.#')# 回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body)# 监听channel.basic_consume(callback,queue=queue_name,no_ack=True)# 开始监听channel.start_consuming() 基于RabbitMQ事项RPC这是程序与程序之间的信息传递,所以起名中间商和服务商 中间商123456789101112131415161718192021222324252627282930313233343536373839404142434445import pikaimport uuidclass FibonacciRpcClient(object): # 连接rabbitMQ def __init__(self): credentials = pika.PlainCredentials("root", "123") self.connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14', credentials=credentials)) self.channel = self.connection.channel() # 随机生成一个消息队列(用于接收结果) result = self.channel.queue_declare(exclusive=True) self.callback_queue = result.method.queue # 监听消息队列中是否有值返回,如果有值则执行 on_response 函数(一旦有结果,则执行on_response) self.channel.basic_consume(self.on_response, no_ack=True,queue=self.callback_queue) def on_response(self, ch, method, props, body): if self.corr_id == props.correlation_id: self.response = body def call(self, n): self.response = None self.corr_id = str(uuid.uuid4()) # 中间商 给 服务商 发送一个任务: 任务id = corr_id / 任务内容 = '30' / 用于接收结果的队列名称 self.channel.basic_publish(exchange='', routing_key='rpc_queue', # 服务商接收任务的队列名称 properties=pika.BasicProperties( reply_to = self.callback_queue, # 用于接收结果的队列 correlation_id = self.corr_id, # 任务ID ), body=str(n)) # 循环监听信息有没有传回来 while self.response is None: # process_data_events也是一直监听有没有值 self.connection.process_data_events() return self.response# 实例化fibonacci_rpc = FibonacciRpcClient()# 调用程序response = fibonacci_rpc.call(50)print('返回结果:',response) 服务商12345678910111213141516171819202122232425262728293031import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 服务商监听任务队列channel.queue_declare(queue='rpc_queue')# 回调函数def on_request(ch, method, props, body): # 接收到内容并处理 n = int(body) response = n + 100 # 把处理好的信息通过队列把它返回回去 ch.basic_publish(exchange='', routing_key=props.reply_to, # 指定队列名称 properties=pika.BasicProperties(correlation_id= props.correlation_id), # 返回id body=str(response)) # body返回的是内容 # 返回一个ack 给服务端发送我接收到了 ch.basic_ack(delivery_tag=method.delivery_tag)# 设置闲置时消费,那个消费者消费完了就接收任务channel.basic_qos(prefetch_count=1)# 监听队列channel.basic_consume(on_request, queue='rpc_queue')# 开始监听channel.start_consuming()]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的常用命令]]></title>
    <url>%2F2019%2F01%2F13%2Fdocker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1.查看docker信息(version,info)12345# 查看版本docker version# 显示docker系统的信息docker info 2.对image的操作(search,pull,images,rmi,history) view plaincopy1234567891011121314# 检索imagedocker search image_name# 下载imagedocker pull image_name# 列出镜像列表:-a, --all=false Show all images; --no-trunc=false Don't truncate output; -q, --quiet=false Only show numeric IDs docker images# 删除一个或多个镜像 -f, --force=false Force; --no-prune=false Do not delete untagged parents docker rmi image_name # 显示一个镜像的历史 --no-trunc=false Don't truncate output; -q, --quiet=false Only show numeric IDs docker history image_name 3.启动容器(run)​ docker容器可以理解为在沙盒中运行的进程,这个沙盒包含该进程所必须的资源,包括文件系统,系统类库,shell环境等,但这个沙盒默认是不会运行任何程序的,你需要在沙盒中运行一个进程来启动某个容器,这个进程是该容器的唯一进程,所以当该进程结束时,容器也会结束 12345678# 在容器中运行"echo" 命令,输出"hello word"docker run image_name echo "hello word"# 交互式进入容器中docker run -i -t image_name /bin/bash# 在容器中安装新的程序docker run image_name apt-get install -y app_name ​ 在执行apt-get 命令的时候，要带上-y参数。如果不指定-y参数的话，apt-get命令会进入交互模式，需要用户输入命令来进行确认，但在docker环境中是无法响应这种交互的。apt-get 命令执行完毕之后，容器就会停止，但对容器的改动不会丢失。 4.查看容器(ps) view plaincopy12345678# 列出当前所有运行的containerdocker ps# 列出所有的containerdocker ps -a# 列出最近一次启动的containerdocker ps -1 5.保存对容器的修改(commit)​ 当你对一个容器进行修改之后(通过容器中运行某一个命令),可以把容器的修改保存下来,这样下一次可以从保存后的最新状态运行该容器 view plaincopy 12# 保存对容器的修改 -a, --author="" Author; -m, --message="" Commit message docker commit ID new_image_name ​ Note:image相当于一个类,container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。 6.对容器的操作(rm、stop、start、kill、logs、diff、top、cp、restart、attach ) view plaincopy1234567891011121314151617181920212223242526272829# 删除所有容器docker rm `docker ps -a -q`# 删除单个容器docker rm Name/ID# 停止,启动,杀死一个容器docker stop Name/IDdocker start Name/IDdocker kill Name/ID# 从一个容器中取日志docker logs Name/ID# 列出一个容器里面被改变的文件或者目录,list列表会显示三种事件,A 增加 D删除 C被改变docker diff Name/ID# 显示一个运行的容器里面的进程信息docker top Name/ID# 从容器里面拷贝文件/目录到本地一个路径docker cp Name:/container_path to_path docker cp ID:/container_path to_path # 重启一个正在运行的容器docker restart Name/ID# 附加到一个运行的容器上docker attach ID ​ Note:attach命令允许你查看或影响一个运行的容器,你可以在同一时间attach同一个容器,你也可以从一个容器中脱离出来,是CTRL + C 7.保存和加载镜像(save load)​ 当需要把一台机器上的镜像迁移到另一台机器上的时候,需要保存于加载镜像 1234567891011# 保存镜像到一个tar包 -o, --output="" Write to an file docker save image_name -o file_path# 加载一个tar包格式的镜像 -i, --input="" Read from a tar archive file docker load -i file_path# 机器adocker save image_name &gt; /home/save.tar# 使用scp将save.tar拷到机器b上,然后docker load &lt; /home/save.tar 8.登录 registry server (login) view plaincopy12# 登录register server -e, --email="" Email; -p, --password="" Password; -u, --username="" Username docker login 9.发布image(push) copy12# 发布docker镜像docker push new_image_name 10.根据Dockerfile构建一个容器1#]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的安装]]></title>
    <url>%2F2019%2F01%2F13%2Fdocker%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[docker安装1.Ubuntu系统Ubuntu安装docker大概要区分为Ubuntu14.04之前和Ubuntu14.04之后两种方法 如果是14.04版本之后的Ubuntu,其内核版本以及一些依赖包都已经准备充分,直接运行下载最新版docker即可: 1curl -sSL https://get.docker.com/ | sh 新安装的系统可能会没有curl服务,需要下载: 1sudo apt-get update $ sudo apt-get install curl 顺便提及,docker应用的启动需要root的管理员权限,最好在安装之前获取root权限,啰嗦一下如何方便地将用户转为root角色 1sudo su 然后根据提示输入当前用户密码即可. 下载好之后可以测试,下载hello-world或者busybox测试一下. 1sudo docker run hello-world docker run是docker的运行命令.后面是容器名称,如果本地没有该命令,则docker服务会从docker仓库下载该容器,然后运行. 测试打印 hello world就说明成功了.可用docker info查看安装信息. 最好使用新版本的Ubuntu安装docker.如果是12.04或者13.04版本的则需要先安装一些依赖性的包 先要升级内核(同样先获取root权限) 12sudo apt-get updatesudo apt-get install linux-image-generic-lts-raring linux-headers-generic-lts-raring Docker有deb格式的安装包 1sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9 后把Docker的库添加到apt的源列表中，更新并安装lxc-docker包。 1234sudo sh -c "echo deb http://get.docker.io/ubuntu docker main\&gt; /etc/apt/sources.list.d/docker.list"sudo apt-get updatesudo apt-get install lxc-docker 如果有警告信息,yes即可 2.centos系统和rhel这两个系统在新的版本里面都自带了docker,只不过docker版本不一定是最新的,我记得centos7里面的自带的docker是0.9,当前最新docker版本已经到了0.11,不过不会影响试用. 系统安装需要保证内核版本在3.10以上,低于这个版本的理论上也可以安装,只不过需要大牛去研究一番,我们直接升级内核 yum安装带aufs模块的3.10内核 123cd /etc/yum.repos.d wget http://www.hop5.in/yum/el6/hop5.repoyum install kernel-ml-aufs kernel-ml-aufs-devel 修改grub的主配置文件/etc/grub.conf，设置default=0，表示第一个title下的内容为默认启动的kernel（一般新安装的内核在第一个位置）,之后重启. 执行安装: 1curl -sSL https://get.docker.com/ | sh 启动服务: 1sudo service docker start 如果是系统版本7以上,已经自带docker包,直接运行: 1yum install docker]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible的基本使用]]></title>
    <url>%2F2019%2F01%2F13%2Fansible%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一.简介ansible是什么东西?官方的title是“Ansible is Simple IT Automation”——简单的自动化IT工具。这个工具的目标有这么几项：让我们自动化部署APP；自动化管理配置项；自动化的持续交付；自动化的（AWS）云服务管理。 所有的这几个目标本质上来说都是在一个台或者几台服务器上，执行一系列的命令而已。就像我之前有介绍过的Fabric，以及我们基于Fabric开发的自动化应用部署的工具： Essay 。都是做了这么个事——批量的在远程服务器上执行命令 。 那么fabric和ansible有什么差别呢？简单来说fabric像是一个工具箱，提供了很多好用的工具，用来在Remote执行命令，而Ansible则是提供了一套简单的流程，你要按照它的流程来做，就能轻松完成任务。这就像是库和框架的关系一样。 当然，它们之间也是有共同点的——都是基于 paramiko 开发的。这个paramiko是什么呢？它是一个纯Python实现的ssh协议库。因此fabric和ansible还有一个共同点就是不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。 二.安装及初步使用 编译安装,此处使用yum 12yum install epel # 下载epel源yum install -y ansible # 安装ansible 2.查看ansible生成的文件 1rpm -ql ansible 3.查看ansible生成的命令 1234ansible # 用来执行ansible的一些命令ansible-doc # 用来查看ansible的模块的帮助信息ansible-playbook # 用来执行playbookansible-galaxy # 用来下载第三方的playbook 4.ansible命令模式 1234567ansible &lt;host-pattern&gt; [options]-a MODULE_ARGS # 模块的参数-C --check # 测试,干跑-f FORKS # 指定并发数--list-hosts # 列出host-pattern主机--syntax-check # 语法检查-m MODULE_NAME # 指定模块 5.ansible第一条命令 1ansible all -m ping # 跟系统自带的ping不一样 6.host-pattern格式 123456789101112131415[web]192.168.19.33192.168.19.44[db]192.168.19.55[cache]192.168.19.66www[001:006].example.com指定所有 all指定单台机器(指定多个机器)指定分组(多个分组)指定分组并集 # ansible "web:db" -m ping指定分组的交集 # ansible "web:&amp;db" -m ping指定分组的差集 # ansible "web:!db" -m ping 7.ansible-doc 12345Usage: ansible-doc [-l|-F|-s] [options] [-t &lt;plugin type&gt; ] [plugin]-a # 列出所有的模块-l # 列出ansible的模块-s # 片段式显示模块的信息 8.补充 123456789[name] #分组name=CentOS-$releasever - Base - mirrors.aliyun.com #这个分组的名字failovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ #分组的url,叫baseurl http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=0 # gpgcheck=1需要验证key文件,gpgcheck=0不验证keyenabled=1 #enabled=1 表示分组可用,enabled=0表示分组是不可用的gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7 #key文件 三.命令相关命令相关1.command 1234ansible web -m aommand "pwd"ansible web -a "chdir=/tmp/ mkdir /data2" # 切换到/tmp并执行pwdansible web -a "creates=/etc/ mkdir /data2" # 判断creates是否存在,真就忽略后面的操作ansible web -a "removes=/tmp/data mkdir /tmp/data2" # 判断removes是否存在,假就忽略后面的操作 2.shell 123ansible web -m shell -a "echo 'test1'|password --stdin test1" # 修改密码ansible 192.168.19.9 -m shell "/root/a.sh" # 指定远程主机上的shell脚本ansible 192.168.19.2 -m shell -a "/root/a.py" # 指定远程主机上的python文件 3.sctipt 1ansible all -m script -a "/root/a.sh" # 执行管控机的shell脚本 文件相关1.copy复制管控机文件到被管控机 123456ansible web -m copy -a "src=/etc/xxx dest=/data/xxx" # src指定源文件 dest指定目标文件ansible web -m copy -a "src=/etc/xxx dest=/data/xxx backup=yes" # backup备份ansible web -m copy -a "src=/etc/init.d dest=/data/" # 复制目录和目录下的文件到远程主机,远程主机也是一个文件夹ansible web -m copy -a "src=/etc/init.d/ dest=/data/" # 复制目录下的文件ansible web -m copy -a "src=/etc/xxx dest=/data/xxx backup=yes mode=600" # mode 指定权限,owner指定文件的属主,group用来指定属组ansible web -m copy -a "content='内容xxxxx' dest=/data10/xx.txt" # content 直接写内容 2.file 1234ansible db -m file -a "path=/data10 state=directory" # path指定地址,state=directory表示创建文件夹ansible db -m file -a "path=/data10/xxx state=touch" # state=touch 表示创建新文件ansible db -m file -a "path=/data10/test1 state=absent" # state=absent 代表删除ansible db -m file -a 'path=/data10/test10 src=/data10/test1 state=link' #src表示源文件,path是不是目标,state=link是不是创建一个软连接 3.fetch 1ansible db -m fetch -a "src=/etc/xxx dest/tmp" # src源地址(在被控机器上),dest目标地址(管控机上的地址)每个管控机的文件都生成了一个目录,会保持文件的原来目录结构 软件相关1.yum 1234ansible web -m yum -a "name=nginx state=installed" # 安装nginxansible web -m shell -a "rpm -qa | grep nginx" # 查看nginx是不是安装成功ansible web -m yum -a "name=nginx state=absent" # 卸载nginxansible web -m yum -a "name=redis,memcached" 2.pip 1ansible web -m pip -a "name=Django==1.11.15" 定时任务 cron 123ansible web -m cron -a "name=testjob minute=4 job='echo 哈哈 &gt; /tmp/xx.txt'" # 创建 name:指定的cron名字 minute:指定分钟 hour:指定小时 day:指定天 month:指定月 weekday:指定周 job:指定要执行的命令ansible web -m cron -a "name=testjob state=absent" # 删除任务ansible web -m cron -a "name=testjob minute=4 disabled=yes job='echo 哈哈 &gt; /tmp/xx.txt'" # disabled=yes表示禁用 用户相关 user 12ansible web -m user -a "name=客户1 home=/data/客户1" # 创建用户并指定家目录ansible web -m user -a "name=客户2 groups='xxx1,xxx2' home=/data/客户2" # groups='xxx1,xxx2' 指定用户的附加组 收集系统信息 setup 收集系统信息 1234567891011121314151617"ansible_all_ipv4_addresses" #ipv4简单信息"ansible_all_ipv6_addresses" #ipv6的简单信息"ansible_architecture": "x86_64", #系统架构"ansible_date_time": #系统时间"ansible_default_ipv4": #详细信息"ansible_devices": #磁盘信息"ansible_distribution_major_version": "7",#系统版本"ansible_distribution": "CentOS", #系统的发行商"ansible_distribution_file_variety": "RedHat", #系统系列"ansible_fqdn": "localhost.localdomain", #系统的主机名"ansible_hostname": "localhost",#简写主机名"ansible_kernel": "3.10.0-693.el7.x86_64", #系统的内核版本"ansible_os_family": "RedHat",# 系统的家族"ansible_processor_vcpus": 2, #cpu的个数"ansible_python_version": "2.7.5", # ansible所用python的版本 ansible web -m setup -a 'filter="*cpu*"' #filter搜索 启动应用 service 123enabled:#开机启动name:#服务的名称state: #操作 四.playbook的基本使用 playbook命令,建议:一个文件做一件事 1.基本格式 12345678ansible-playbook [options] playbook.yml-C # 干跑,检查-f FORKS # 用来做并发,来指定并发数--list-hosts #列出执行命令的主机--syntax-check # 检查语法--list-tasks #列出playbook要执行的任务列表-t TAGS, #指定要运行到tags-e EXTRA_VARS #给playbook传递变量 2.单个playbook 12345678#单个playbook- hosts: web #指定要运行命令的主机 remote_user: root # 指定运行命令的用户 tasks: #任务列表 - name: mkdir # 任务1,name是必须的 file: path=/data state=directory # 指定的模块: 模块的参数 - name: copyfile copy: src=/etc/fstab dest=/data/f 3.多个playbook 1234567891011121314##多个playbook- hosts: web remote_user: root tasks: - name: mkdir file: path=/data state=directory - name: copyfile copy: src=/etc/fstab dest=/data/f- hosts: db remote_user: root tasks: - name: wget shell: "wget -O /data/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo" 4.指定tags 123456789##指定tags- hosts: web remote_user: root tasks: - name: mkdir file: path=/data state=directory - name: copyfile copy: src=/etc/fstab dest=/data/f tags: copyfile 变量1.第一种 123456## 传递变量 -e"key=value"- hosts: web remote_user: root tasks: - name: yum &#123;&#123;pkg_name&#125;&#125; pkg yum: name=&#123;&#123;pkg_name&#125;&#125; 2.第二种 1234567- hosts: web remote_user: root vars: - pkg_name: memcached tasks: - name: yum &#123;&#123;pkg_name&#125;&#125; pkg yum: name=&#123;&#123;pkg_name&#125;&#125; 3.第三种 1234#在hosts文件里面写,值可以不同[web]192.168.19.9 pkg_name=nginx192.168.19.26 pkg_name=redis 4.第四种 12[web:vars]pkg_name=nginx 5.变量的应用顺序 1-e &gt; yml文件 &gt; hosts文件 #命令行里面是最高的,hosts文件是最低的 条件 when 条件判断 123456789- hosts: cache remote_user: root tasks: - name: copyfile1 copy: content='wusir zhenchou' dest=/tmp/a.txt when: ansible_os_family=="RedHat" #只有为真的时候才会执行上面的操作 - name: copyfile2 copy: content='alex gengchou' dest=/tmp/b.txt when: ansible_os_family=="OpenBSD" 循环with_items1.循环单个 12345678910111213- hosts: cache remote_user: root tasks: - name: create user user: name=&#123;&#123;item&#125;&#125; ## 循环下面的with_items with_items: - yuchao - yantao - name: create group group: name=&#123;&#123;item&#125;&#125;## 循环下面的with_items with_items: - yuchao2 - yantao2 2.循环嵌套 12345678910111213- hosts: cache remote_user: root tasks: - name: create group group: name=&#123;&#123;item&#125;&#125; with_items: - yuchao4 - yantao4 - name: create user user: name=&#123;&#123;item.name&#125;&#125; group=&#123;&#123;item.group&#125;&#125; #可以通过字典取值 with_items: - &#123;"name":yuchao3,"group":yuchao4&#125; - &#123;"name":yantao3,"group":yuchao4&#125; 模板文件1.模板的基本使用 12345678910- hosts: cache remote_user: root tasks: - name: install redis yum: name=redis - name: copyfile template: src=redis.conf.j2 dest=/etc/redis.conf ## 模板基于jinja2 - name: start service: name=redis state=started #模板文件放在templates,可以直接用相对路径去调用配置文件 roles(高级使用) 作用 结构清晰 可以重用 结构 12345tasks #目录是必须的,存放任务templates #是存放模板vars #用来存放变量 ### 切记,不能加-,加-报错files #用来存放文件mkdir -p &#123;nginx,uwsgi,mysql&#125;/&#123;tasks,templates,vars,files&#125; #创建目录结构的命令 补充生成公私钥 1ssh-keygen 复制公钥到远程主机 1ssh-copy-id 192.168.19.99 ping命令发送的是ICMP协议 查看用户相关 1234tail -l /etc/shadow 查看最后一个用户echo "testl" | password --stdin testl 设置用户密码,不需要二次确useradd # 创建用户默认的家目录在/home -d 可以指定用户的家目录groupadd # 用来创建用户组,用户组没有家目录 创建链接 12ln 创建硬链接 链接文件变更 源文件不变ln -s 创建软连接 链接文件变更 源文件变 pip的基本使用 123pip freeze &gt; file # 给当前的python模块做快照pip install -r xxx.txt # 安装pip list # 查看所有的python模块 crontab定时任务 1234567* */5 * * * job #/n 表示每隔n 0 */5 * * 3,6 job #3,6 表示周三和周六## 切记 最前面不能用*,表示每时每刻都在执行,一定要有一个时间## 应用场景: 打包日志,定期的同步时间,备份-e # 编辑-l # 列出-r # 删除 启动应用 12systemctl restart nginx # centos7中的操作应用service nginx restart # centos6里面的操作 查看系统内存使用量 1free -m 查看系统的内存使用量 Ad-hoc:命令行的意思 mv 的使用 1mv redis.conf&#123;,.j2&#125; == mv redis.conf redis.conf.j2 yum和rpm的基本使用 1234yum remove 卸载rpm redhat pk manageyum 自动解决依赖关系rpm 不会自动解决依赖关系 CI和CD的基本使用 12CI 持续交付 jenkins maven war包CD 持续集成 脚本去做 docker (最大的一个作用,到处运行 ) k8s 暂时关闭防火墙 1setenforce 0 #暂时关闭selinux uwsgi的配置 1234567891011121314151617[uwsgi]http = :8000 #端口#the local unix socket file than commnuincate to Nginxsocket = /data/mysite/mysite.socket #socket 只能本机使用# the base directory (full path)chdir = /data/mysite #当前工作目录# Django's wsgi filewsgi-file = mysite/wsgi.py #要执行的文件# maximum number of worker processesprocesses = 4 #进程数#thread numbers startched in each worker processthreads = 2 #线程数# clear environment on exitvacuum = truedaemonize = /data/mysite/uwsgi.log #后台启动,并提供日志py-autoreload=1 #py文件变更后uwsgi自动重启 kill -9 可以杀死父进程 启动uwsgi 1uwsgi --http :8000 --module mysite.wsgi ## --http 启动的端口 --module 项目.wsgi文件]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
</search>
